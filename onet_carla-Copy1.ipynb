{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6953b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.layers import ResnetBlockFC\n",
    "from torch_scatter import scatter_mean, scatter_max\n",
    "from src.common import coordinate2index, normalize_coordinate, normalize_3d_coordinate, map2local\n",
    "from src.encoder.unet import UNet\n",
    "from src.encoder.unet3d import UNet3D\n",
    "\n",
    "\n",
    "class LocalPoolPointnet(nn.Module):\n",
    "    ''' PointNet-based encoder network with ResNet blocks for each point.\n",
    "        Number of input points are fixed.\n",
    "    \n",
    "    Args:\n",
    "        c_dim (int): dimension of latent code c\n",
    "        dim (int): input points dimension\n",
    "        hidden_dim (int): hidden dimension of the network\n",
    "        scatter_type (str): feature aggregation when doing local pooling\n",
    "        unet (bool): weather to use U-Net\n",
    "        unet_kwargs (str): U-Net parameters\n",
    "        unet3d (bool): weather to use 3D U-Net\n",
    "        unet3d_kwargs (str): 3D U-Net parameters\n",
    "        plane_resolution (int): defined resolution for plane feature\n",
    "        grid_resolution (int): defined resolution for grid feature \n",
    "        plane_type (str): feature type, 'xz' - 1-plane, ['xz', 'xy', 'yz'] - 3-plane, ['grid'] - 3D grid volume\n",
    "        padding (float): conventional padding paramter of ONet for unit cube, so [-0.5, 0.5] -> [-0.55, 0.55]\n",
    "        n_blocks (int): number of blocks ResNetBlockFC layers\n",
    "    '''\n",
    "\n",
    "    def __init__(self, c_dim=128, dim=3, hidden_dim=128, scatter_type='max', \n",
    "                 unet=False, unet_kwargs=None, unet3d=False, unet3d_kwargs=None, \n",
    "                 plane_resolution=None, grid_resolution=None, plane_type='xz', padding=0.1, n_blocks=5):\n",
    "        super().__init__()\n",
    "        self.c_dim = c_dim\n",
    "\n",
    "        self.fc_pos = nn.Linear(dim, 2*hidden_dim)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResnetBlockFC(2*hidden_dim, hidden_dim) for i in range(n_blocks)\n",
    "        ])\n",
    "        self.fc_c = nn.Linear(hidden_dim, c_dim)\n",
    "\n",
    "        self.actvn = nn.ReLU()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        if unet:\n",
    "            self.unet = UNet(c_dim, in_channels=c_dim, **unet_kwargs)\n",
    "        else:\n",
    "            self.unet = None\n",
    "\n",
    "        if unet3d:\n",
    "            self.unet3d = UNet3D(**unet3d_kwargs)\n",
    "        else:\n",
    "            self.unet3d = None\n",
    "\n",
    "        self.reso_plane = plane_resolution\n",
    "        self.reso_grid = grid_resolution\n",
    "        self.plane_type = plane_type\n",
    "        self.padding = padding\n",
    "\n",
    "        if scatter_type == 'max':\n",
    "            self.scatter = scatter_max\n",
    "        elif scatter_type == 'mean':\n",
    "            self.scatter = scatter_mean\n",
    "        else:\n",
    "            raise ValueError('incorrect scatter type')\n",
    "\n",
    "\n",
    "    def generate_plane_features(self, p, c, plane='xz'):\n",
    "        # acquire indices of features in plane\n",
    "        xy = normalize_coordinate(p.clone(), plane=plane, padding=self.padding) # normalize to the range of (0, 1)\n",
    "        index = coordinate2index(xy, self.reso_plane)\n",
    "\n",
    "        # scatter plane features from points\n",
    "        fea_plane = c.new_zeros(p.size(0), self.c_dim, self.reso_plane**2)\n",
    "        c = c.permute(0, 2, 1) # B x 512 x T\n",
    "        fea_plane = scatter_mean(c, index, out=fea_plane) # B x 512 x reso^2\n",
    "        fea_plane = fea_plane.reshape(p.size(0), self.c_dim, self.reso_plane, self.reso_plane) # sparce matrix (B x 512 x reso x reso)\n",
    "\n",
    "        # process the plane features with UNet\n",
    "        if self.unet is not None:\n",
    "            fea_plane = self.unet(fea_plane)\n",
    "\n",
    "        return fea_plane\n",
    "\n",
    "    def generate_grid_features(self, p, c):\n",
    "        p_nor = normalize_3d_coordinate(p.clone(), padding=self.padding)\n",
    "        index = coordinate2index(p_nor, self.reso_grid, coord_type='3d')\n",
    "        # scatter grid features from points\n",
    "        fea_grid = c.new_zeros(p.size(0), self.c_dim, self.reso_grid**3)\n",
    "        c = c.permute(0, 2, 1)\n",
    "        fea_grid = scatter_mean(c, index, out=fea_grid) # B x C x reso^3\n",
    "        fea_grid = fea_grid.reshape(p.size(0), self.c_dim, self.reso_grid, self.reso_grid, self.reso_grid) # sparce matrix (B x 512 x reso x reso)\n",
    "\n",
    "        if self.unet3d is not None:\n",
    "            fea_grid = self.unet3d(fea_grid)\n",
    "\n",
    "        return fea_grid\n",
    "\n",
    "    def pool_local(self, xy, index, c):\n",
    "        bs, fea_dim = c.size(0), c.size(2)\n",
    "        keys = xy.keys()\n",
    "\n",
    "        c_out = 0\n",
    "        for key in keys:\n",
    "            # scatter plane features from points\n",
    "            if key == 'grid':\n",
    "                fea = self.scatter(c.permute(0, 2, 1), index[key], dim_size=self.reso_grid**3)\n",
    "            else:\n",
    "                fea = self.scatter(c.permute(0, 2, 1), index[key], dim_size=self.reso_plane**2)\n",
    "            if self.scatter == scatter_max:\n",
    "                fea = fea[0]\n",
    "            # gather feature back to points\n",
    "            fea = fea.gather(dim=2, index=index[key].expand(-1, fea_dim, -1))\n",
    "            c_out += fea\n",
    "        return c_out.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "    def forward(self, p):\n",
    "        batch_size, T, D = p.size()\n",
    "\n",
    "        # acquire the index for each point\n",
    "        coord = {}\n",
    "        index = {}\n",
    "        if 'xz' in self.plane_type:\n",
    "            coord['xz'] = normalize_coordinate(p.clone(), plane='xz', padding=self.padding)\n",
    "            index['xz'] = coordinate2index(coord['xz'], self.reso_plane)\n",
    "        if 'xy' in self.plane_type:\n",
    "            coord['xy'] = normalize_coordinate(p.clone(), plane='xy', padding=self.padding)\n",
    "            index['xy'] = coordinate2index(coord['xy'], self.reso_plane)\n",
    "        if 'yz' in self.plane_type:\n",
    "            coord['yz'] = normalize_coordinate(p.clone(), plane='yz', padding=self.padding)\n",
    "            index['yz'] = coordinate2index(coord['yz'], self.reso_plane)\n",
    "        if 'grid' in self.plane_type:\n",
    "            coord['grid'] = normalize_3d_coordinate(p.clone(), padding=self.padding)\n",
    "            index['grid'] = coordinate2index(coord['grid'], self.reso_grid, coord_type='3d')\n",
    "        \n",
    "        net = self.fc_pos(p)\n",
    "\n",
    "        net = self.blocks[0](net)\n",
    "        for block in self.blocks[1:]:\n",
    "            pooled = self.pool_local(coord, index, net)\n",
    "            net = torch.cat([net, pooled], dim=2)\n",
    "            net = block(net)\n",
    "\n",
    "        c = self.fc_c(net)\n",
    "\n",
    "        fea = {}\n",
    "        if 'grid' in self.plane_type:\n",
    "            fea['grid'] = self.generate_grid_features(p, c)\n",
    "        if 'xz' in self.plane_type:\n",
    "            fea['xz'] = self.generate_plane_features(p, c, plane='xz')\n",
    "        if 'xy' in self.plane_type:\n",
    "            fea['xy'] = self.generate_plane_features(p, c, plane='xy')\n",
    "        if 'yz' in self.plane_type:\n",
    "            fea['yz'] = self.generate_plane_features(p, c, plane='yz')\n",
    "\n",
    "        return fea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c522b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.layers import ResnetBlockFC\n",
    "from src.common import normalize_coordinate, normalize_3d_coordinate, map2local\n",
    "\n",
    "\n",
    "class LocalDecoder(nn.Module):\n",
    "    ''' Decoder.\n",
    "        Instead of conditioning on global features, on plane/volume local features.\n",
    "\n",
    "    Args:\n",
    "        dim (int): input dimension\n",
    "        c_dim (int): dimension of latent conditioned code c\n",
    "        hidden_size (int): hidden size of Decoder network\n",
    "        n_blocks (int): number of blocks ResNetBlockFC layers\n",
    "        leaky (bool): whether to use leaky ReLUs\n",
    "        sample_mode (str): sampling feature strategy, bilinear|nearest\n",
    "        padding (float): conventional padding paramter of ONet for unit cube, so [-0.5, 0.5] -> [-0.55, 0.55]\n",
    "    '''\n",
    "\n",
    "    def __init__(self, dim=3, c_dim=128,\n",
    "                 hidden_size=256, n_blocks=5, leaky=False, sample_mode='bilinear', padding=0.1):\n",
    "        super().__init__()\n",
    "        self.c_dim = c_dim\n",
    "        self.n_blocks = n_blocks\n",
    "\n",
    "        if c_dim != 0:\n",
    "            self.fc_c = nn.ModuleList([\n",
    "                nn.Linear(c_dim, hidden_size) for i in range(n_blocks)\n",
    "            ])\n",
    "\n",
    "\n",
    "        self.fc_p = nn.Linear(dim, hidden_size)\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResnetBlockFC(hidden_size) for i in range(n_blocks)\n",
    "        ])\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        if not leaky:\n",
    "            self.actvn = F.relu\n",
    "        else:\n",
    "            self.actvn = lambda x: F.leaky_relu(x, 0.2)\n",
    "\n",
    "        self.sample_mode = sample_mode\n",
    "        self.padding = padding\n",
    "    \n",
    "\n",
    "    def sample_plane_feature(self, p, c, plane='xz'):\n",
    "        xy = normalize_coordinate(p.clone(), plane=plane, padding=self.padding) # normalize to the range of (0, 1)\n",
    "        xy = xy[:, :, None].float()\n",
    "        vgrid = 2.0 * xy - 1.0 # normalize to (-1, 1)\n",
    "        c = F.grid_sample(c, vgrid, padding_mode='border', align_corners=True, mode=self.sample_mode).squeeze(-1)\n",
    "        return c\n",
    "\n",
    "    def sample_grid_feature(self, p, c):\n",
    "        p_nor = normalize_3d_coordinate(p.clone(), padding=self.padding) # normalize to the range of (0, 1)\n",
    "        p_nor = p_nor[:, :, None, None].float()\n",
    "#         print(np.unique(p.clone().cpu().numpy()),np.unique(p_nor.cpu().numpy()))\n",
    "        vgrid = 2.0 * p_nor - 1.0 # normalize to (-1, 1)\n",
    "        # acutally trilinear interpolation if mode = 'bilinear'\n",
    "        c = F.grid_sample(c, vgrid, padding_mode='border', align_corners=True, mode=self.sample_mode).squeeze(-1).squeeze(-1)\n",
    "        return c\n",
    "\n",
    "\n",
    "    def forward(self, p, c_plane, **kwargs):\n",
    "        if self.c_dim != 0:\n",
    "            plane_type = list(c_plane.keys())\n",
    "            c = 0\n",
    "            if 'grid' in plane_type:\n",
    "                c += self.sample_grid_feature(p, c_plane['grid'])\n",
    "            if 'xz' in plane_type:\n",
    "                c += self.sample_plane_feature(p, c_plane['xz'], plane='xz')\n",
    "            if 'xy' in plane_type:\n",
    "                c += self.sample_plane_feature(p, c_plane['xy'], plane='xy')\n",
    "            if 'yz' in plane_type:\n",
    "                c += self.sample_plane_feature(p, c_plane['yz'], plane='yz')\n",
    "            c = c.transpose(1, 2)\n",
    "\n",
    "        p = p.float()\n",
    "        net = self.fc_p(p)\n",
    "\n",
    "        for i in range(self.n_blocks):\n",
    "            if self.c_dim != 0:\n",
    "                net = net + self.fc_c[i](c)\n",
    "\n",
    "            net = self.blocks[i](net)\n",
    "\n",
    "        out = self.fc_out(self.actvn(net))\n",
    "        out = out.squeeze(-1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c3b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CON\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import distributions as dist\n",
    "# from src.conv_onet.models import decoder\n",
    "\n",
    "\n",
    "class ConvolutionalOccupancyNetwork(nn.Module):\n",
    "    ''' Occupancy Network class.\n",
    "\n",
    "    Args:\n",
    "        decoder (nn.Module): decoder network\n",
    "        encoder (nn.Module): encoder network\n",
    "        device (device): torch device\n",
    "    '''\n",
    "\n",
    "    def __init__(self, decoder, encoder=None, device=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.decoder = decoder.to(device)\n",
    "\n",
    "        if encoder is not None:\n",
    "            self.encoder = encoder.to(device)\n",
    "        else:\n",
    "            self.encoder = None\n",
    "\n",
    "        self._device = device\n",
    "\n",
    "    def forward(self, p, inputs, sample=True, **kwargs):\n",
    "        ''' Performs a forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            p (tensor): sampled points\n",
    "            inputs (tensor): conditioning input\n",
    "            sample (bool): whether to sample for z\n",
    "        '''\n",
    "        #############\n",
    "        if isinstance(p, dict):\n",
    "            batch_size = p['p'].size(0)\n",
    "        else:\n",
    "            batch_size = p.size(0)\n",
    "        c = self.encode_inputs(inputs)\n",
    "        p_r = self.decode(p, c, **kwargs)\n",
    "        return p_r\n",
    "\n",
    "    def encode_inputs(self, inputs):\n",
    "        ''' Encodes the input.\n",
    "\n",
    "        Args:\n",
    "            input (tensor): the input\n",
    "        '''\n",
    "\n",
    "        if self.encoder is not None:\n",
    "            c = self.encoder(inputs)\n",
    "        else:\n",
    "            # Return inputs?\n",
    "            c = torch.empty(inputs.size(0), 0)\n",
    "\n",
    "        return c\n",
    "\n",
    "    def decode(self, p, c, **kwargs):\n",
    "        ''' Returns occupancy probabilities for the sampled points.\n",
    "\n",
    "        Args:\n",
    "            p (tensor): points\n",
    "            c (tensor): latent conditioned code c\n",
    "        '''\n",
    "\n",
    "        logits = self.decoder(p, c, **kwargs)\n",
    "        p_r = dist.Bernoulli(logits=logits)\n",
    "        return p_r\n",
    "\n",
    "    def to(self, device):\n",
    "        ''' Puts the model to the device.\n",
    "\n",
    "        Args:\n",
    "            device (device): pytorch device\n",
    "        '''\n",
    "        model = super().to(device)\n",
    "        model._device = device\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30a3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsamplePointcloud(object):\n",
    "    ''' Point cloud subsampling transformation class.\n",
    "\n",
    "    It subsamples the point cloud data.\n",
    "\n",
    "    Args:\n",
    "        N (int): number of points to be subsampled\n",
    "    '''\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "\n",
    "    def __call__(self, data):\n",
    "        ''' Calls the transformation.\n",
    "\n",
    "        Args:\n",
    "            data (dict): data dictionary\n",
    "        '''\n",
    "        data_out = data.copy()\n",
    "        points = data[None]\n",
    "        normals = data['normals']\n",
    "\n",
    "        indices = np.random.randint(points.shape[0], size=self.N)\n",
    "        data_out[None] = points[indices, :]\n",
    "        data_out['normals'] = normals[indices, :]\n",
    "\n",
    "        return data_out\n",
    "    \n",
    "    \n",
    "class SubsamplePoints(object):\n",
    "    ''' Points subsampling transformation class.\n",
    "\n",
    "    It subsamples the points data.\n",
    "\n",
    "    Args:\n",
    "        N (int): number of points to be subsampled\n",
    "    '''\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "\n",
    "    def __call__(self, data):\n",
    "        ''' Calls the transformation.\n",
    "\n",
    "        Args:\n",
    "            data (dictionary): data dictionary\n",
    "        '''\n",
    "\n",
    "        points = data[None]\n",
    "        occ = data['occ']\n",
    "\n",
    "        data_out = data.copy()\n",
    "        if isinstance(self.N, int):\n",
    "            idx = np.random.randint(points.shape[0], size=self.N)\n",
    "            data_out.update({\n",
    "                None: points[idx, :],\n",
    "                'occ':  occ[idx],\n",
    "            })\n",
    "#         else:\n",
    "#             Nt_out, Nt_in = self.N\n",
    "#             occ_binary = (occ >= 0.5)\n",
    "#             points0 = points[~occ_binary]\n",
    "#             points1 = points[occ_binary]\n",
    "\n",
    "#             idx0 = np.random.randint(points0.shape[0], size=Nt_out)\n",
    "#             idx1 = np.random.randint(points1.shape[0], size=Nt_in)\n",
    "\n",
    "#             points0 = points0[idx0, :]\n",
    "#             points1 = points1[idx1, :]\n",
    "#             points = np.concatenate([points0, points1], axis=0)\n",
    "\n",
    "#             occ0 = np.zeros(Nt_out, dtype=np.float32)\n",
    "#             occ1 = np.ones(Nt_in, dtype=np.float32)\n",
    "#             occ = np.concatenate([occ0, occ1], axis=0)\n",
    "\n",
    "#             volume = occ_binary.sum() / len(occ_binary)\n",
    "#             volume = volume.astype(np.float32)\n",
    "\n",
    "#             data_out.update({\n",
    "#                 None: points,\n",
    "#                 'occ': occ,\n",
    "#                 'volume': volume,\n",
    "#             })\n",
    "        return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0085b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carla Dataloader \n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import random\n",
    "# import json\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset\n",
    "# from torch.utils import data\n",
    "\n",
    "# class CarlaDataset(Dataset):\n",
    "#     \"\"\"Carla Simulation Dataset for 3D mapping project\n",
    "    \n",
    "#     Access to the processed data, including evaluation labels predictions velodyne poses times\n",
    "#     \"\"\"\n",
    "#     def __init__(self, directory,\n",
    "#         device='cuda',\n",
    "#         num_frames=1,\n",
    "#         voxelize_input=False,\n",
    "#         binary_counts=True,\n",
    "#         random_flips=False,       \n",
    "#         ):\n",
    "#         '''Constructor.\n",
    "#         Parameters:\n",
    "#             directory: directory to the dataset\n",
    "#         '''\n",
    "\n",
    "#         self.voxelize_input = voxelize_input\n",
    "#         self.binary_counts = binary_counts\n",
    "#         self._directory = directory\n",
    "#         self._num_frames = num_frames\n",
    "#         self.device = device\n",
    "#         self.random_flips = random_flips\n",
    "        \n",
    "#         self._scenes = sorted(os.listdir(self._directory))\n",
    "#         self._scenes = [os.path.join(scene, \"cartesian\") for scene in self._scenes]\n",
    "\n",
    "#         self._num_scenes = len(self._scenes)\n",
    "#         self._num_frames_scene = []\n",
    "\n",
    "#         self._velodyne_list = []\n",
    "#         self._eval_labels = []\n",
    "#         self._frames_list = []\n",
    "\n",
    "#         for scene in self._scenes:\n",
    "#             velodyne_dir = os.path.join(self._directory, scene, 'pointcloud')\n",
    "#             eval_dir = os.path.join(self._directory, scene, 'points')\n",
    "#             self._num_frames_scene.append(len(os.listdir(velodyne_dir)))\n",
    "            \n",
    "#             frames_list = [os.path.splitext(filename)[0] for filename in sorted(os.listdir(velodyne_dir))]\n",
    "#             self._frames_list.extend(frames_list)\n",
    "\n",
    "#             self._velodyne_list.extend([os.path.join(velodyne_dir, 'pointcloud_' + str(frame).zfill(6) +'.npz') for frame in range(len(frames_list))])\n",
    "#             self._eval_labels.extend([os.path.join(eval_dir, 'points_' + str(frame).zfill(6) +'.npz') for frame in range(len(frames_list))])\n",
    "\n",
    "#         self._cum_num_frames = np.cumsum(np.array(self._num_frames_scene) - self._num_frames + 1)\n",
    "#     # Use all frames, if there is no data then zero pad\n",
    "#     def __len__(self):\n",
    "#         return sum(self._num_frames_scene)\n",
    "    \n",
    "#     def collate_fn(self, batch):\n",
    "#         #input_batch = [bi[0] for bi in data]\n",
    "# #         output_batch = [bi[1] for bi in data]\n",
    "#         #return input_batch\n",
    "        \n",
    "#         batch = list(filter(lambda x: x is not None, batch))\n",
    "#         return data.dataloader.default_collate(batch)\n",
    "\n",
    "#     def get_file_path(self, idx):\n",
    "#         print(self._frames_list[idx])\n",
    "\n",
    "        \n",
    "#     def __getitem__(self, idx):\n",
    "\n",
    "#         pointcloud = np.load(self._velodyne_list[idx])\n",
    "#         points = np.load(self._eval_labels[idx])\n",
    "        \n",
    "#         pc_field = {}\n",
    "#         pc_field[None] = pointcloud['points']\n",
    "#         pc_field['normals'] = pointcloud['normals']\n",
    "        \n",
    "#         pc_field_sub = SubsamplePointcloud(10000)\n",
    "#         pc_field = pc_field_sub(pc_field)\n",
    "        \n",
    "#         points_field = {}\n",
    "#         points_field[None] = points['points']\n",
    "#         points_field['occ'] = points['occupancies']\n",
    "        \n",
    "#         points_field_sub = SubsamplePoints(2048)\n",
    "#         points_field = points_field_sub(points_field)\n",
    "        \n",
    "# #         print(pc_field[None].shape, pc_field['normals'].shape)\n",
    "# #         print(points_field[None].shape, points_field['occupancies'].shape)\n",
    "        \n",
    "#         fields = {}\n",
    "#         data = {}\n",
    "        \n",
    "#         #for pc_field,points_field in carla_ds:\n",
    "\n",
    "#         fields['points'] = points_field\n",
    "        \n",
    "#         if pc_field is not None:\n",
    "#             fields['inputs'] = pc_field\n",
    "\n",
    "#         for field_name, field in fields.items():\n",
    "#             field_data = field\n",
    "#             for k, v in field_data.items():\n",
    "#                 if k is None:\n",
    "#                     data[field_name] = v\n",
    "#                 else:\n",
    "#                     data['%s.%s' % (field_name, k)] = v\n",
    "# #         print(data['points'].shape, data['points.occ'].shape, data['inputs'].shape)\n",
    "#         return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6baab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(compressed):\n",
    "    ''' given a bit encoded voxel grid, make a normal voxel grid out of it.  '''\n",
    "    uncompressed = np.zeros(compressed.shape[0] * 8, dtype=np.uint8)\n",
    "    uncompressed[::8] = compressed[:] >> 7 & 1\n",
    "    uncompressed[1::8] = compressed[:] >> 6 & 1\n",
    "    uncompressed[2::8] = compressed[:] >> 5 & 1\n",
    "    uncompressed[3::8] = compressed[:] >> 4 & 1\n",
    "    uncompressed[4::8] = compressed[:] >> 3 & 1\n",
    "    uncompressed[5::8] = compressed[:] >> 2 & 1\n",
    "    uncompressed[6::8] = compressed[:] >> 1 & 1\n",
    "    uncompressed[7::8] = compressed[:] & 1\n",
    "\n",
    "    return uncompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5602621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add points along ray to grid\n",
    "def ray_trace_batch(points, labels, sample_spacing):\n",
    "\n",
    "    # Compute samples using array broadcasting\n",
    "    vec_norms_temp = np.linalg.norm(points, axis=1)\n",
    "\n",
    "    # filter out zero norms\n",
    "    points = points[vec_norms_temp != 0]\n",
    "    labels = labels[vec_norms_temp != 0]\n",
    "    vec_norms = np.reshape(vec_norms_temp[vec_norms_temp != 0], (-1,1))\n",
    "    # vec_norms = np.reshape(np.linalg.norm(points, axis=1), (-1, 1))\n",
    "\n",
    "    vec_angles = points / vec_norms\n",
    "\n",
    "    difs = np.reshape(np.arange(0.0, 100.0, sample_spacing), (1, -1, 1))\n",
    "    difs = np.reshape(vec_angles, (-1, 1, 3)) * difs\n",
    "    new_samples = np.reshape(points, (-1, 1, 3)) - difs\n",
    "    # Create labels\n",
    "    new_labels = np.zeros((new_samples.shape[0], new_samples.shape[1]), dtype=np.uint8)\n",
    "    new_labels[:, 0] = labels\n",
    "    new_labels = new_labels.reshape(-1)\n",
    "\n",
    "    # Remove points with dist < 0\n",
    "    vec_dists = new_samples / np.reshape(vec_angles, (-1, 1, 3))\n",
    "    first_pts = vec_dists[:, 0, 0]\n",
    "    good_samples = np.reshape(new_samples[vec_dists[:, :, 0] > 0], (-1, 3))\n",
    "    good_labels = new_labels[vec_dists[:, :, 0].reshape(-1) > 0]\n",
    "\n",
    "    return good_samples, good_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7dfad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rellis3d dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils import data\n",
    "\n",
    "class RellisDataset(Dataset):\n",
    "    \"\"\"Rellis3D Dataset for convOccn\n",
    "    \n",
    "    Access to the processed data, including evaluation labels predictions velodyne poses times\n",
    "    \"\"\"\n",
    "    def __init__(self, directory,\n",
    "        device='cuda',\n",
    "        num_frames=1,\n",
    "        voxelize_input=False,\n",
    "        binary_counts=True,\n",
    "        random_flips=False,   \n",
    "        model_setting = 'train'\n",
    "        ):\n",
    "        '''Constructor.\n",
    "        Parameters:\n",
    "            directory: directory to the dataset\n",
    "        '''\n",
    "\n",
    "        self.voxelize_input = voxelize_input\n",
    "        self.binary_counts = binary_counts\n",
    "        self._directory = directory\n",
    "        self._num_frames = num_frames\n",
    "        self.device = device\n",
    "        self.random_flips = random_flips\n",
    "        self.sampling_dist = 1.5\n",
    "        \n",
    "#         self._scenes = sorted(os.listdir(self._directory))\n",
    "        self._scenes = [ s for s in sorted(os.listdir(self._directory)) if s.isdigit() ]\n",
    "\n",
    "        self._num_scenes = len(self._scenes)\n",
    "        self._num_frames_scene = 0\n",
    "        \n",
    "        self._velodyne_list = []\n",
    "        self._poses = []\n",
    "        self._frames_list = []\n",
    "        self._num_frames_by_scene = []\n",
    "        \n",
    "        split_dir = os.path.join(self._directory, \"pt_\"+model_setting+\".lst\")\n",
    "\n",
    "        # Generate list of scenes and indices to iterate over\n",
    "        self._scenes_list = []\n",
    "        self._index_list = []\n",
    "\n",
    "        with open(split_dir, 'r') as split_file:\n",
    "            for line in split_file:\n",
    "                image_path = line.split(' ')\n",
    "                image_path_lst = image_path[0].split('/')\n",
    "                scene_num = image_path_lst[0]\n",
    "                frame_index = int(image_path_lst[2][0:6])\n",
    "                self._scenes_list.append(scene_num)\n",
    "                self._index_list.append(frame_index)\n",
    "                \n",
    "        for scene_id in range(self._num_scenes):\n",
    "            scene_name = self._scenes[scene_id]\n",
    "            velodyne_dir = os.path.join(self._directory, scene_name, 'velodyne')\n",
    "            # Load all poses and frame indices regardless of mode\n",
    "            self._poses.append(np.loadtxt(os.path.join(self._directory, scene_name, 'poses.txt')).reshape(-1, 12) )\n",
    "            self._frames_list.append([os.path.splitext(filename)[0] for filename in sorted(os.listdir(velodyne_dir))])\n",
    "            self._num_frames_by_scene.append(len(self._frames_list[scene_id]))\n",
    "#             print(\"nf:\", self._num_frames_by_scene)\n",
    "            # PC inputs\n",
    "            self._velodyne_list.append( [os.path.join(velodyne_dir, \n",
    "                str(frame).zfill(6)+'.bin') for frame in self._frames_list[scene_id]] )\n",
    "        \n",
    "        # Get number of frames to iterate over\n",
    "        self._num_frames_scene = len(self._index_list)\n",
    "            \n",
    "\n",
    "#         for i in range(len(self._scenes_list)):\n",
    "#             scene_name = self._scenes_list[i]\n",
    "#             velodyne_dir = os.path.join(self._directory, scene_name, 'velodyne')\n",
    "#             self._poses.append(np.loadtxt(os.path.join(self._directory, scene_name, 'poses.txt')).reshape(-1, 12) )\n",
    "#             self._frames_list.append([os.path.splitext(filename)[0] for filename in sorted(os.listdir(velodyne_dir))])\n",
    "#             self._num_frames_scene += 1\n",
    "            \n",
    "#             #self._velodyne_list.extend([os.path.join(velodyne_dir, str(self._index_list[i]).zfill(6) + '.bin')])\n",
    "#             self._velodyne_list.append( [os.path.join(velodyne_dir, \n",
    "#                 str(frame).zfill(6)+'.bin') for frame in self._frames_list[i]] )\n",
    "\n",
    "\n",
    "    def get_pose(self, scene_id, frame_id):\n",
    "        pose = np.zeros((4, 4))\n",
    "        pose[3, 3] = 1\n",
    "        pose[:3, :4] = self._poses[scene_id][frame_id].reshape(3, 4)\n",
    "        return pose\n",
    "        \n",
    "        \n",
    "    # Use all frames, if there is no data then zero pad\n",
    "    def __len__(self):\n",
    "#         return sum(self._num_frames_scene)\n",
    "        return self._num_frames_scene\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        batch = list(filter(lambda x: x is not None, batch))\n",
    "        return data.dataloader.default_collate(batch)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        scene_name  = self._scenes_list[idx]\n",
    "        scene_id    = int(scene_name)       # Scene ID\n",
    "        frame_id    = self._index_list[idx] # Frame ID in current scene ID\n",
    "        \n",
    "        points = []\n",
    "        points_occ = []\n",
    "        \n",
    "        # pointcloud\n",
    "        pointcloud = np.fromfile(self._velodyne_list[scene_id][frame_id],dtype=np.float32).reshape(-1,4)[:,:3]\n",
    "\n",
    "        frame_range = frame_id # remove leading 0s\n",
    "#         if frame_range > 20:\n",
    "#             frame_range = 20\n",
    "        frame_range = 1\n",
    "        \n",
    "        ego_pose = self.get_pose(scene_id, frame_id)\n",
    "        to_ego   = np.linalg.inv(ego_pose)\n",
    "        \n",
    "        for i in range(frame_range):\n",
    "            velodyne = np.fromfile(self._velodyne_list[scene_id][frame_id - i],dtype=np.float32).reshape(-1,4)\n",
    "#             print('range{}, scene{}, frame{}'.format(i, scene_id, frame_id - i))\n",
    "#             print('x:', self._velodyne_list[scene_id][frame_id - i])\n",
    "            velodyne[:,3] = 1            \n",
    "            \n",
    "            to_world = self.get_pose(scene_id, frame_id - i)\n",
    "            relative_pose = np.matmul(to_ego, to_world)\n",
    "            \n",
    "            points_t = velodyne[:,:3]\n",
    "            points_occ_t = velodyne[:,3]\n",
    "            \n",
    "            if i == 0: # current frame\n",
    "                points_t, points_occ_t = ray_trace_batch(points_t, points_occ_t, self.sampling_dist)\n",
    "#                 print('rt:',points_t.shape, points_occ_t.shape)\n",
    "#                 print(np.unique(points_occ_t, return_counts=True))\n",
    "            points_t = np.dot(relative_pose[:3, :3], points_t.T).T + relative_pose[:3, 3] # transfrom to current frame coordiantes\n",
    "            \n",
    "            # filter points outside the voxel grid\n",
    "            min_bound = [-25.6, -25.6, -2]\n",
    "            max_bound = [25.6, 25.6, 1.2]\n",
    "            grid_point_mask= np.all(\n",
    "            (points_t < max_bound) & (points_t >= min_bound), axis=1)\n",
    "            points_t = points_t[grid_point_mask,:]\n",
    "            points_occ_t = points_occ_t[grid_point_mask]\n",
    "            \n",
    "            points.extend(points_t)\n",
    "            points_occ.extend(points_occ_t)\n",
    "        \n",
    "        points = np.asarray(points)\n",
    "        points_occ = np.asarray(points_occ)\n",
    "#         print('points:', points_occ.shape)\n",
    "#         print('occ:', np.sum(points_occ == 1))\n",
    "#         pointcloud = np.fromfile(self._velodyne_list[idx],dtype=np.float32).reshape(-1,4)[:,:3]\n",
    "\n",
    "#         points_occ = velodyne[:,3]\n",
    "        \n",
    "#         mask = points_occ != 0\n",
    "#         points_occ = points_occ[mask]\n",
    "# #         print(np.unique(points_occ, return_counts=True))\n",
    "        \n",
    "#         # points\n",
    "#         min_bound = [-25.6, -25.6, -2]\n",
    "#         max_bound = [25.6, 25.6, 1.2]\n",
    "#         grid_size = [256, 256, 16]\n",
    "#         coor_ranges = min_bound + max_bound\n",
    "#         voxel_sizes = [abs(coor_ranges[3] - coor_ranges[0]) / grid_size[0], \n",
    "#                     abs(coor_ranges[4] - coor_ranges[1]) / grid_size[1],\n",
    "#                     abs(coor_ranges[5] - coor_ranges[2]) / grid_size[2]]\n",
    "\n",
    "#         x = np.linspace(min_bound[0], max_bound[0], num=int(grid_size[0])) + voxel_sizes[0] / 2\n",
    "#         y = np.linspace(min_bound[1], max_bound[1], num=int(grid_size[1])) + voxel_sizes[1] / 2\n",
    "#         z = np.linspace(min_bound[2], max_bound[2], num=int(grid_size[2])) + voxel_sizes[2] / 2\n",
    "#         xv, yv, zv = np.meshgrid(x, y, z, indexing=\"ij\")\n",
    "\n",
    "#         points = np.stack((xv, yv, zv))\n",
    "#         points = np.moveaxis(points,0,-1).reshape(-1,3)\n",
    "#         points = points[mask]\n",
    "        \n",
    "#         # Filter points outside of voxel grid\n",
    "#         grid_point_mask= np.all(\n",
    "#             (pointcloud < max_bound) & (pointcloud >= min_bound), axis=1)\n",
    "#         pointcloud = pointcloud[grid_point_mask, :]\n",
    "        \n",
    "        # normalize\n",
    "#         pc_sums = pointcloud.sum(axis=1, keepdims=True)\n",
    "#         pointcloud /= (2 * pc_sums)\n",
    "        pointcloud /= (2*np.max(pointcloud))\n",
    "\n",
    "#         pointcloud = np.linalg.norm(pointcloud, axis=1)\n",
    "        \n",
    "#         p_sums = points.sum(axis=1, keepdims=True)\n",
    "#         points /= (2 * p_sums)\n",
    "        points /= (2*np.max(points))\n",
    "        #pointcloud /= (2*np.max(pointcloud))\n",
    "        #points /= (2*np.max(points))\n",
    "        \n",
    "        \n",
    "        \n",
    "#         print('nm:',np.unique(pointcloud, return_counts=True))\n",
    "#         print('p:',np.unique(pointcloud, return_counts=True))\n",
    "        \n",
    "#         pocc_t = copy.deepcopy(points_occ)\n",
    "        \n",
    "#         points_occ[pocc_t != 40] = 1\n",
    "#         points_occ[pocc_t == 40] = 0\n",
    "#         points_occ[points_occ == 40] = 0\n",
    "#         points_occ[points_occ != 0 ] = 1\n",
    "                \n",
    "        pc_field = {}\n",
    "        pc_field[None] = pointcloud\n",
    "        pc_field['normals'] = np.zeros((pointcloud.shape[0],1))\n",
    "    \n",
    "        pc_field_sub = SubsamplePointcloud(10000) #10000, 131072\n",
    "        pc_field = pc_field_sub(pc_field)\n",
    "        \n",
    "\n",
    "        # normalize points\n",
    "        \n",
    "        points_field = {}\n",
    "        points_field[None] = points\n",
    "        points_field['occ'] = points_occ\n",
    "        \n",
    "        points_field_sub = SubsamplePoints(2048) #2048, 131072\n",
    "        points_field = points_field_sub(points_field)\n",
    "#         print('occ_sample',np.sum(points_field['occ'] == 1))\n",
    "        \n",
    "    #         print(pc_field[None].shape, pc_field['normals'].shape)\n",
    "    #         print(points_field[None].shape, points_field['occupancies'].shape)\n",
    "        \n",
    "        fields = {}\n",
    "        data = {}\n",
    "        \n",
    "        #for pc_field,points_field in carla_ds:\n",
    "\n",
    "        fields['points'] = points_field\n",
    "        \n",
    "        if pc_field is not None:\n",
    "            fields['inputs'] = pc_field\n",
    "\n",
    "        for field_name, field in fields.items():\n",
    "            field_data = field\n",
    "            for k, v in field_data.items():\n",
    "                if k is None:\n",
    "                    data[field_name] = v\n",
    "                else:\n",
    "                    data['%s.%s' % (field_name, k)] = v\n",
    "#         print(data['points'].shape, data['points.occ'].shape, data['inputs'].shape)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c7bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "r3d_dir = \"/home/jason/rellis3d\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "carla_ds_train = RellisDataset(directory=r3d_dir, device=device, model_setting='train')\n",
    "carla_ds_eval = RellisDataset(directory=r3d_dir, device=device, model_setting='val')\n",
    "\n",
    "dataloader_train = DataLoader(carla_ds_train, batch_size=32, shuffle=True, collate_fn=carla_ds_train.collate_fn, num_workers=8)\n",
    "dataloader_eval = DataLoader(carla_ds_eval, batch_size=1, shuffle=False, collate_fn=carla_ds_eval.collate_fn, num_workers=4)\n",
    "# o1= next(iter(Dataloader))\n",
    "#print(list(o1[0].keys()), list(o2[0].keys()))\n",
    "# test = o2[0]\n",
    "# nz = np.sum(test!=0)\n",
    "# print(o2[0].shape, nz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bc74826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalOccupancyNetwork(\n",
      "  (decoder): LocalDecoder(\n",
      "    (fc_c): ModuleList(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (fc_p): Linear(in_features=3, out_features=32, bias=True)\n",
      "    (blocks): ModuleList(\n",
      "      (0): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "      )\n",
      "      (1): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "      )\n",
      "      (2): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "      )\n",
      "      (3): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "      )\n",
      "      (4): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (fc_out): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      "  (encoder): LocalPoolPointnet(\n",
      "    (fc_pos): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (blocks): ModuleList(\n",
      "      (0): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "        (shortcut): Linear(in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "      (1): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "        (shortcut): Linear(in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "      (2): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "        (shortcut): Linear(in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "      (3): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "        (shortcut): Linear(in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "      (4): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "        (shortcut): Linear(in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (fc_c): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (actvn): ReLU()\n",
      "    (unet3d): UNet3D(\n",
      "      (encoders): ModuleList(\n",
      "        (0): Encoder(\n",
      "          (basic_module): DoubleConv(\n",
      "            (SingleConv1): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "            (SingleConv2): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Encoder(\n",
      "          (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "          (basic_module): DoubleConv(\n",
      "            (SingleConv1): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "            (SingleConv2): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Encoder(\n",
      "          (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "          (basic_module): DoubleConv(\n",
      "            (SingleConv1): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "            (SingleConv2): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoders): ModuleList(\n",
      "        (0): Decoder(\n",
      "          (upsampling): Upsampling()\n",
      "          (basic_module): DoubleConv(\n",
      "            (SingleConv1): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "            (SingleConv2): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Decoder(\n",
      "          (upsampling): Upsampling()\n",
      "          (basic_module): DoubleConv(\n",
      "            (SingleConv1): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "            (SingleConv2): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_conv): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (final_activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model (configs/pointcloud/room_grid32.yaml)\n",
    "# src.conv_onet.config.py get_model\n",
    "\n",
    "encoder_kwargs = {'hidden_dim': 32,\n",
    "                  'plane_type': 'grid',\n",
    "                  'grid_resolution': 32, #32\n",
    "                  'unet3d': True,\n",
    "                  'unet3d_kwargs': {\n",
    "                    'num_levels': 3,#3\n",
    "                    'f_maps': 32,\n",
    "                    'in_channels': 32,\n",
    "                    'out_channels': 32}}\n",
    "\n",
    "decoder_kwargs = {\n",
    "    'sample_mode': 'bilinear', # bilinear / nearest\n",
    "    'hidden_size': 32 }\n",
    "\n",
    "c_dim = 32\n",
    "dim = 3\n",
    "padding = 0.1\n",
    "decoder = LocalDecoder(dim=dim, c_dim=c_dim, padding=padding,\n",
    "        **decoder_kwargs)\n",
    "\n",
    "encoder = LocalPoolPointnet(dim=dim, c_dim=c_dim, padding=padding,\n",
    "            **encoder_kwargs)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ConvolutionalOccupancyNetwork(\n",
    "        decoder, encoder, device=device\n",
    "    )\n",
    "\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc8539c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loss \n",
    "\n",
    "def compute_loss(data):\n",
    "    ''' Computes the loss.\n",
    "\n",
    "    Args:\n",
    "        data (dict): data dictionary\n",
    "    '''    \n",
    "    p = data.get('points').to(device)\n",
    "    occ = data.get('points.occ').to(device)\n",
    "    inputs = data.get('inputs', torch.empty(p.size(0), 0)).to(device)\n",
    "\n",
    "    if 'pointcloud_crop' in data.keys():\n",
    "        # add pre-computed index\n",
    "        inputs = add_key(inputs, data.get('inputs.ind'), 'points', 'index', device=device)\n",
    "        inputs['mask'] = data.get('inputs.mask').to(device)\n",
    "        # add pre-computed normalized coordinates\n",
    "        p = add_key(p, data.get('points.normalized'), 'p', 'p_n', device=device)\n",
    "\n",
    "    c = model.encode_inputs(inputs)\n",
    "\n",
    "    kwargs = {}\n",
    "    # General points\n",
    "    logits = model.decode(p, c, **kwargs).logits\n",
    "    loss_i = F.binary_cross_entropy_with_logits(\n",
    "        logits, occ.float(), reduction='none')\n",
    "    loss = loss_i.sum(-1).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b87fc58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute iou\n",
    "def compute_iou(occ1, occ2):\n",
    "    ''' Computes the Intersection over Union (IoU) value for two sets of\n",
    "    occupancy values.\n",
    "\n",
    "    Args:\n",
    "        occ1 (tensor): first set of occupancy values\n",
    "        occ2 (tensor): second set of occupancy values\n",
    "    '''\n",
    "    occ1 = np.asarray(occ1)\n",
    "    occ2 = np.asarray(occ2)\n",
    "\n",
    "    # Put all data in second dimension\n",
    "    # Also works for 1-dimensional data\n",
    "    if occ1.ndim >= 2:\n",
    "        occ1 = occ1.reshape(occ1.shape[0], -1)\n",
    "    if occ2.ndim >= 2:\n",
    "        occ2 = occ2.reshape(occ2.shape[0], -1)\n",
    "\n",
    "    # Convert to boolean values\n",
    "    occ1 = (occ1 >= 0.5)\n",
    "    occ2 = (occ2 >= 0.5)\n",
    "\n",
    "    # Compute IOU\n",
    "    area_union = (occ1 | occ2).astype(np.float32).sum(axis=-1)\n",
    "    area_intersect = (occ1 & occ2).astype(np.float32).sum(axis=-1)\n",
    "    \n",
    "#     print(area_union, area_intersect)\n",
    "\n",
    "    iou = (area_intersect / area_union)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def eval_step(data):\n",
    "    model.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "147b2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Intersection, union for one frame\n",
    "def iou_one_frame(pred, target, n_classes=23):\n",
    "    pred = np.asarray(pred)\n",
    "    target = np.asarray(target)\n",
    "    pred = pred.reshape(-1)\n",
    "    target = target.reshape(-1)\n",
    "    intersection = np.zeros(n_classes)\n",
    "    union = np.zeros(n_classes)\n",
    "\n",
    "    for cls in range(n_classes):\n",
    "        pred_inds = pred == cls\n",
    "        target_inds = target == cls\n",
    "        intersection[cls] = (pred_inds[target_inds]).sum() # Cast to long to prevent overflows\n",
    "        union[cls] = pred_inds.sum() + target_inds.sum() - intersection[cls]\n",
    "    return intersection, union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca08fa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] it=050, loss=764.3213, acc=0.8566, iou=0.5238, oiou=0.1960\n",
      "[Epoch 00] it=100, loss=609.1907, acc=0.8889, iou=0.6469, oiou=0.4152\n",
      "[Epoch 00] it=150, loss=579.2969, acc=0.8924, iou=0.6542, oiou=0.4259\n",
      "[Epoch 00] it=200, loss=550.4482, acc=0.8973, iou=0.6695, oiou=0.4497\n",
      "acc_eval:0.89, iou_eval:0.6556, oiou_eval:0.4253\n",
      "[Epoch 01] it=250, loss=526.0677, acc=0.9013, iou=0.6811, oiou=0.4684\n",
      "[Epoch 01] it=300, loss=519.8085, acc=0.9025, iou=0.6860, oiou=0.4765\n",
      "[Epoch 01] it=350, loss=491.9928, acc=0.9073, iou=0.6976, oiou=0.4939\n",
      "[Epoch 01] it=400, loss=484.2381, acc=0.9070, iou=0.6962, oiou=0.4922\n",
      "[Epoch 01] it=450, loss=463.2542, acc=0.9106, iou=0.7077, oiou=0.5096\n",
      "acc_eval:0.90, iou_eval:0.6595, oiou_eval:0.4292\n",
      "[Epoch 02] it=500, loss=458.4711, acc=0.9116, iou=0.7081, oiou=0.5096\n",
      "[Epoch 02] it=550, loss=447.2506, acc=0.9127, iou=0.7131, oiou=0.5174\n",
      "[Epoch 02] it=600, loss=447.0770, acc=0.9127, iou=0.7131, oiou=0.5172\n",
      "[Epoch 02] it=650, loss=433.0774, acc=0.9152, iou=0.7211, oiou=0.5293\n",
      "[Epoch 02] it=700, loss=425.9214, acc=0.9163, iou=0.7237, oiou=0.5338\n",
      "acc_eval:0.90, iou_eval:0.6616, oiou_eval:0.4289\n",
      "[Epoch 03] it=750, loss=414.9451, acc=0.9184, iou=0.7298, oiou=0.5435\n",
      "[Epoch 03] it=800, loss=410.8126, acc=0.9190, iou=0.7330, oiou=0.5482\n",
      "[Epoch 03] it=850, loss=412.9438, acc=0.9181, iou=0.7301, oiou=0.5449\n",
      "[Epoch 03] it=900, loss=414.2778, acc=0.9182, iou=0.7289, oiou=0.5416\n",
      "[Epoch 03] it=950, loss=390.9439, acc=0.9223, iou=0.7417, oiou=0.5631\n",
      "acc_eval:0.90, iou_eval:0.6850, oiou_eval:0.4787\n",
      "[Epoch 04] it=1000, loss=393.9630, acc=0.9218, iou=0.7425, oiou=0.5645\n",
      "[Epoch 04] it=1050, loss=391.8982, acc=0.9218, iou=0.7403, oiou=0.5609\n",
      "[Epoch 04] it=1100, loss=380.7597, acc=0.9238, iou=0.7471, oiou=0.5730\n",
      "[Epoch 04] it=1150, loss=374.6203, acc=0.9250, iou=0.7503, oiou=0.5790\n",
      "[Epoch 04] it=1200, loss=374.6918, acc=0.9249, iou=0.7509, oiou=0.5791\n",
      "acc_eval:0.90, iou_eval:0.6818, oiou_eval:0.4688\n",
      "[Epoch 05] it=1250, loss=373.7685, acc=0.9248, iou=0.7516, oiou=0.5798\n",
      "[Epoch 05] it=1300, loss=360.1309, acc=0.9273, iou=0.7590, oiou=0.5915\n",
      "[Epoch 05] it=1350, loss=361.2781, acc=0.9272, iou=0.7585, oiou=0.5928\n",
      "[Epoch 05] it=1400, loss=361.2995, acc=0.9270, iou=0.7598, oiou=0.5936\n",
      "[Epoch 05] it=1450, loss=354.0981, acc=0.9286, iou=0.7622, oiou=0.5993\n",
      "acc_eval:0.90, iou_eval:0.6801, oiou_eval:0.4661\n",
      "[Epoch 06] it=1500, loss=347.8069, acc=0.9298, iou=0.7672, oiou=0.6068\n",
      "[Epoch 06] it=1550, loss=350.3628, acc=0.9292, iou=0.7649, oiou=0.6028\n",
      "[Epoch 06] it=1600, loss=339.1364, acc=0.9314, iou=0.7719, oiou=0.6153\n",
      "[Epoch 06] it=1650, loss=337.9896, acc=0.9315, iou=0.7741, oiou=0.6173\n",
      "[Epoch 06] it=1700, loss=339.4435, acc=0.9310, iou=0.7720, oiou=0.6150\n",
      "acc_eval:0.90, iou_eval:0.6836, oiou_eval:0.4724\n",
      "[Epoch 07] it=1750, loss=340.0936, acc=0.9309, iou=0.7708, oiou=0.6138\n",
      "[Epoch 07] it=1800, loss=333.2751, acc=0.9322, iou=0.7759, oiou=0.6218\n",
      "[Epoch 07] it=1850, loss=330.2130, acc=0.9326, iou=0.7757, oiou=0.6217\n",
      "[Epoch 07] it=1900, loss=332.1213, acc=0.9321, iou=0.7750, oiou=0.6207\n",
      "[Epoch 07] it=1950, loss=326.7610, acc=0.9336, iou=0.7809, oiou=0.6289\n",
      "acc_eval:0.90, iou_eval:0.6860, oiou_eval:0.4798\n",
      "[Epoch 08] it=2000, loss=326.6841, acc=0.9330, iou=0.7783, oiou=0.6261\n",
      "[Epoch 08] it=2050, loss=321.8027, acc=0.9344, iou=0.7832, oiou=0.6344\n",
      "[Epoch 08] it=2100, loss=320.1093, acc=0.9346, iou=0.7831, oiou=0.6341\n",
      "[Epoch 08] it=2150, loss=321.7598, acc=0.9343, iou=0.7822, oiou=0.6318\n",
      "acc_eval:0.90, iou_eval:0.6888, oiou_eval:0.4841\n",
      "[Epoch 09] it=2200, loss=315.7412, acc=0.9356, iou=0.7868, oiou=0.6409\n",
      "[Epoch 09] it=2250, loss=313.7116, acc=0.9359, iou=0.7880, oiou=0.6415\n",
      "[Epoch 09] it=2300, loss=312.1429, acc=0.9360, iou=0.7885, oiou=0.6435\n",
      "[Epoch 09] it=2350, loss=311.5760, acc=0.9359, iou=0.7870, oiou=0.6417\n",
      "[Epoch 09] it=2400, loss=308.4097, acc=0.9367, iou=0.7910, oiou=0.6474\n",
      "acc_eval:0.90, iou_eval:0.6901, oiou_eval:0.4850\n",
      "[Epoch 10] it=2450, loss=306.1459, acc=0.9370, iou=0.7906, oiou=0.6471\n",
      "[Epoch 10] it=2500, loss=302.3294, acc=0.9379, iou=0.7950, oiou=0.6539\n",
      "[Epoch 10] it=2550, loss=305.2641, acc=0.9371, iou=0.7913, oiou=0.6481\n",
      "[Epoch 10] it=2600, loss=303.8273, acc=0.9375, iou=0.7929, oiou=0.6510\n",
      "[Epoch 10] it=2650, loss=299.9432, acc=0.9383, iou=0.7949, oiou=0.6545\n",
      "acc_eval:0.90, iou_eval:0.6874, oiou_eval:0.4805\n",
      "[Epoch 11] it=2700, loss=297.3587, acc=0.9389, iou=0.7981, oiou=0.6599\n",
      "[Epoch 11] it=2750, loss=295.4723, acc=0.9389, iou=0.7977, oiou=0.6579\n",
      "[Epoch 11] it=2800, loss=298.6740, acc=0.9381, iou=0.7953, oiou=0.6548\n",
      "[Epoch 11] it=2850, loss=293.0508, acc=0.9394, iou=0.7984, oiou=0.6611\n",
      "[Epoch 11] it=2900, loss=297.8855, acc=0.9389, iou=0.7965, oiou=0.6576\n",
      "acc_eval:0.91, iou_eval:0.6906, oiou_eval:0.4850\n",
      "[Epoch 12] it=2950, loss=292.2068, acc=0.9395, iou=0.7993, oiou=0.6621\n",
      "[Epoch 12] it=3000, loss=288.9566, acc=0.9401, iou=0.8000, oiou=0.6632\n",
      "[Epoch 12] it=3050, loss=288.4148, acc=0.9403, iou=0.8030, oiou=0.6683\n",
      "[Epoch 12] it=3100, loss=287.2863, acc=0.9406, iou=0.8026, oiou=0.6669\n",
      "[Epoch 12] it=3150, loss=290.3067, acc=0.9398, iou=0.8001, oiou=0.6634\n",
      "acc_eval:0.90, iou_eval:0.6865, oiou_eval:0.4778\n",
      "[Epoch 13] it=3200, loss=287.8477, acc=0.9405, iou=0.8016, oiou=0.6655\n",
      "[Epoch 13] it=3250, loss=280.1494, acc=0.9420, iou=0.8078, oiou=0.6764\n",
      "[Epoch 13] it=3300, loss=285.8611, acc=0.9405, iou=0.8029, oiou=0.6679\n",
      "[Epoch 13] it=3350, loss=283.2277, acc=0.9414, iou=0.8054, oiou=0.6726\n",
      "[Epoch 13] it=3400, loss=284.4911, acc=0.9408, iou=0.8038, oiou=0.6687\n",
      "acc_eval:0.90, iou_eval:0.6902, oiou_eval:0.4859\n",
      "[Epoch 14] it=3450, loss=283.0868, acc=0.9411, iou=0.8049, oiou=0.6718\n",
      "[Epoch 14] it=3500, loss=279.6168, acc=0.9419, iou=0.8073, oiou=0.6758\n",
      "[Epoch 14] it=3550, loss=279.5033, acc=0.9419, iou=0.8069, oiou=0.6758\n",
      "[Epoch 14] it=3600, loss=276.0975, acc=0.9429, iou=0.8095, oiou=0.6783\n",
      "[Epoch 14] it=3650, loss=276.3904, acc=0.9425, iou=0.8090, oiou=0.6786\n",
      "acc_eval:0.90, iou_eval:0.6867, oiou_eval:0.4801\n",
      "[Epoch 15] it=3700, loss=276.8227, acc=0.9424, iou=0.8090, oiou=0.6778\n",
      "[Epoch 15] it=3750, loss=278.3413, acc=0.9420, iou=0.8078, oiou=0.6763\n",
      "[Epoch 15] it=3800, loss=278.8109, acc=0.9418, iou=0.8077, oiou=0.6757\n",
      "[Epoch 15] it=3850, loss=275.5602, acc=0.9425, iou=0.8093, oiou=0.6781\n",
      "[Epoch 15] it=3900, loss=273.8227, acc=0.9433, iou=0.8101, oiou=0.6808\n",
      "acc_eval:0.90, iou_eval:0.6854, oiou_eval:0.4772\n",
      "[Epoch 16] it=3950, loss=274.2720, acc=0.9427, iou=0.8090, oiou=0.6784\n",
      "[Epoch 16] it=4000, loss=269.2557, acc=0.9438, iou=0.8119, oiou=0.6834\n",
      "[Epoch 16] it=4050, loss=270.7145, acc=0.9435, iou=0.8127, oiou=0.6850\n",
      "[Epoch 16] it=4100, loss=269.1479, acc=0.9439, iou=0.8140, oiou=0.6873\n",
      "acc_eval:0.90, iou_eval:0.6884, oiou_eval:0.4855\n",
      "[Epoch 17] it=4150, loss=269.9360, acc=0.9437, iou=0.8134, oiou=0.6853\n",
      "[Epoch 17] it=4200, loss=272.1910, acc=0.9432, iou=0.8109, oiou=0.6818\n",
      "[Epoch 17] it=4250, loss=266.5852, acc=0.9444, iou=0.8146, oiou=0.6881\n",
      "[Epoch 17] it=4300, loss=265.5888, acc=0.9447, iou=0.8165, oiou=0.6911\n",
      "[Epoch 17] it=4350, loss=273.0821, acc=0.9429, iou=0.8109, oiou=0.6813\n",
      "acc_eval:0.90, iou_eval:0.6876, oiou_eval:0.4819\n",
      "[Epoch 18] it=4400, loss=268.8387, acc=0.9437, iou=0.8135, oiou=0.6856\n",
      "[Epoch 18] it=4450, loss=261.2466, acc=0.9455, iou=0.8185, oiou=0.6941\n",
      "[Epoch 18] it=4500, loss=264.1462, acc=0.9445, iou=0.8142, oiou=0.6875\n",
      "[Epoch 18] it=4550, loss=264.4451, acc=0.9447, iou=0.8161, oiou=0.6903\n",
      "[Epoch 18] it=4600, loss=265.1867, acc=0.9446, iou=0.8155, oiou=0.6896\n",
      "acc_eval:0.90, iou_eval:0.6844, oiou_eval:0.4745\n",
      "[Epoch 19] it=4650, loss=263.3985, acc=0.9448, iou=0.8173, oiou=0.6923\n",
      "[Epoch 19] it=4700, loss=255.5583, acc=0.9467, iou=0.8216, oiou=0.6987\n",
      "[Epoch 19] it=4750, loss=262.8924, acc=0.9448, iou=0.8169, oiou=0.6920\n",
      "[Epoch 19] it=4800, loss=262.7264, acc=0.9448, iou=0.8169, oiou=0.6913\n",
      "[Epoch 19] it=4850, loss=263.1724, acc=0.9447, iou=0.8162, oiou=0.6913\n",
      "acc_eval:0.90, iou_eval:0.6883, oiou_eval:0.4831\n",
      "[Epoch 20] it=4900, loss=258.1388, acc=0.9460, iou=0.8198, oiou=0.6971\n",
      "[Epoch 20] it=4950, loss=259.4147, acc=0.9457, iou=0.8197, oiou=0.6971\n",
      "[Epoch 20] it=5000, loss=255.3200, acc=0.9466, iou=0.8207, oiou=0.6978\n",
      "[Epoch 20] it=5050, loss=260.0390, acc=0.9455, iou=0.8189, oiou=0.6949\n",
      "[Epoch 20] it=5100, loss=258.9101, acc=0.9456, iou=0.8186, oiou=0.6953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_eval:0.90, iou_eval:0.6867, oiou_eval:0.4801\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16820/1769143958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import shutil\n",
    "import copy\n",
    "\n",
    "save_dir = '/home/jason/convolutional_occupancy_networks_og/out/r3d_model/'\n",
    "write_dir = '/home/jason/convolutional_occupancy_networks_og/out/r3d_sw/'\n",
    "writer = SummaryWriter(write_dir)\n",
    "seed = 42\n",
    "# setup_seed(seed)\n",
    "lr = 0.001\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "decayRate = 0.96\n",
    "epoch_num = 10000\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(BETA1, BETA2))\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "device = 'cuda'\n",
    "print_every = 50\n",
    "\n",
    "it = 0\n",
    "loss_kt = 0\n",
    "iou_kt = 0\n",
    "iou_og_kt = 0\n",
    "acc_kt = 0\n",
    "best_iou = 0\n",
    "\n",
    "velo_dir = '/home/jason/rellis3d/00000/velodyne'\n",
    "output_dir = '/home/jason/convolutional_occupancy_networks_og/out/r3d_out/'\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "    \n",
    "if os.path.exists(save_dir):\n",
    "    shutil.rmtree(save_dir)\n",
    "    \n",
    "if os.path.exists(write_dir):\n",
    "    shutil.rmtree(write_dir)\n",
    "\n",
    "os.mkdir(output_dir)\n",
    "os.mkdir(save_dir)\n",
    "os.mkdir(write_dir)\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "\n",
    "    model.train()\n",
    "    for batch in dataloader_train:\n",
    "\n",
    "        it += 1\n",
    "\n",
    "        # Training\n",
    "        optimizer.zero_grad()\n",
    "        loss = compute_loss(batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_kt += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # acc\n",
    "            points = batch['points'].to(device)\n",
    "            points_occ = batch['points.occ'].to(device)\n",
    "            inputs = batch['inputs'].to(device)\n",
    "            \n",
    "            p_out = model(points, inputs)\n",
    "\n",
    "            occ = (points_occ >= 0.5).cpu().numpy()\n",
    "            occ_hat = (p_out.probs >= 0.5).cpu().numpy()\n",
    "            acc = np.sum(occ == occ_hat, axis = 1) / occ.shape[1]\n",
    "\n",
    "            intersection, union = iou_one_frame(occ, occ_hat, 2)\n",
    "            mIou = np.mean(intersection / union)\n",
    "            iou_kt += mIou\n",
    "            \n",
    "            og_iou = compute_iou(occ, occ_hat).mean()\n",
    "            iou_og_kt += og_iou\n",
    "            \n",
    "            acc_batch = np.mean(acc)\n",
    "            acc_kt += acc_batch\n",
    "            \n",
    "            # Record\n",
    "            writer.add_scalar('/Loss/Train', loss.item(), it)\n",
    "            writer.add_scalar('/Accuracy/Train', acc_batch, it)\n",
    "            writer.add_scalar('/mIoU/Train', mIou, it)\n",
    "            writer.add_scalar('/OGmIoU/Train', og_iou, it)\n",
    "                \n",
    "        if it % print_every == 0 :\n",
    "            print(\"[Epoch %02d] it=%03d, loss=%.4f, acc=%.4f, iou=%.4f, oiou=%.4f\" % (epoch, it,loss_kt/print_every, acc_kt/print_every, iou_kt/print_every, iou_og_kt/print_every))\n",
    "            loss_kt = 0\n",
    "            iou_kt = 0\n",
    "            iou_og_kt = 0\n",
    "            acc_kt = 0\n",
    "        \n",
    "    my_lr_scheduler.step()\n",
    "    \n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    acc_batches = 0\n",
    "    iou = 0\n",
    "    iou_og = 0\n",
    "    with torch.no_grad():\n",
    "        for bt in dataloader_eval:\n",
    "            points = bt['points'].to(device)\n",
    "            points_occ = bt['points.occ'].to(device)\n",
    "            inputs = bt['inputs'].to(device)\n",
    "\n",
    "            p_out = model(points, inputs)\n",
    "\n",
    "            occ = (points_occ >= 0.5).cpu().numpy()\n",
    "            occ_hat = (p_out.probs >= 0.5).cpu().numpy()\n",
    "            acc = np.sum(occ == occ_hat, axis = 1) / occ.shape[1]\n",
    "            acc_batch = np.mean(acc)        \n",
    "            acc_batches += acc_batch\n",
    "            \n",
    "            intersection, union = iou_one_frame(occ, occ_hat, 2)\n",
    "            mIou = np.mean(intersection/union)\n",
    "            iou += mIou\n",
    "            \n",
    "            omIou = compute_iou(occ, occ_hat).mean()\n",
    "            iou_og += omIou\n",
    "            \n",
    "            # Record\n",
    "            writer.add_scalar('/Accuracy/Val', acc_batch, it)\n",
    "            writer.add_scalar('/mIoU/Val', mIou, it)\n",
    "            writer.add_scalar('/OGmIoU/Val', iou_og, it)\n",
    "\n",
    "    acc_batches /= len(dataloader_eval)\n",
    "    iou /= len(dataloader_eval)\n",
    "    iou_og /= len(dataloader_eval)\n",
    "    print(\"acc_eval:%.2f, iou_eval:%.4f, oiou_eval:%.4f\" % (acc_batches, iou, iou_og))\n",
    "    \n",
    "    \n",
    "#     if iou >= best_iou:\n",
    "#         best_iou = iou\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, \"Epoch\" + str(epoch) + \".pt\"))\n",
    "\n",
    "    # Generate output        \n",
    "\n",
    "    # use frame 100 - 150:\n",
    "    with torch.no_grad():\n",
    "\n",
    "        out_dir_ep = os.path.join(output_dir, \"Epoch\" + str(epoch))\n",
    "\n",
    "        if not os.path.exists(out_dir_ep):\n",
    "            os.mkdir(out_dir_ep)\n",
    "\n",
    "        for j in range(100,150):\n",
    "    #                 # points\n",
    "            min_bound = [-25.6, -25.6, -2]\n",
    "            max_bound = [25.6, 25.6, 1.2]\n",
    "    #                 grid_size = [256, 256, 16]\n",
    "    #                 coor_ranges = min_bound + max_bound\n",
    "    #                 voxel_sizes = [abs(coor_ranges[3] - coor_ranges[0]) / grid_size[0], \n",
    "    #                             abs(coor_ranges[4] - coor_ranges[1]) / grid_size[1],\n",
    "    #                             abs(coor_ranges[5] - coor_ranges[2]) / grid_size[2]]\n",
    "\n",
    "    #                 x = np.linspace(min_bound[0], max_bound[0], num=int(grid_size[0])) + voxel_sizes[0] / 2\n",
    "    #                 y = np.linspace(min_bound[1], max_bound[1], num=int(grid_size[1])) + voxel_sizes[1] / 2\n",
    "    #                 z = np.linspace(min_bound[2], max_bound[2], num=int(grid_size[2])) + voxel_sizes[2] / 2\n",
    "    #                 xv, yv, zv = np.meshgrid(x, y, z, indexing=\"ij\")\n",
    "\n",
    "    #                 points_t = np.stack((xv, yv, zv))\n",
    "    #                 points_t = np.moveaxis(points_t,0,-1).reshape(-1,3)\n",
    "    #                 points_t /= (2*np.max(points_t))\n",
    "\n",
    "            pc_dir = os.path.join(velo_dir, str(j).zfill(6) + '.bin')\n",
    "            pc_t = np.fromfile(pc_dir,dtype=np.float32).reshape(-1,4)\n",
    "            pc_t[:,3] = 1\n",
    "            inputs_t = copy.deepcopy(pc_t[:,:3])  \n",
    "            points_t = copy.deepcopy(pc_t[:,:3]) \n",
    "            points_occ_t = copy.deepcopy(pc_t[:,3])\n",
    "\n",
    "            points_t, points_occ_t = ray_trace_batch(points_t, points_occ_t, 1.5)\n",
    "\n",
    "            grid_point_mask= np.all(\n",
    "                (inputs_t < max_bound) & (inputs_t >= min_bound), axis=1)\n",
    "            \n",
    "            grid_point_mask_p= np.all(\n",
    "                (points_t < max_bound) & (points_t >= min_bound), axis=1)\n",
    "\n",
    "            inputs_t = inputs_t[grid_point_mask, :]\n",
    "            points_t = points_t[grid_point_mask_p, :]\n",
    "            points_occ_t = points_occ_t[grid_point_mask_p]\n",
    "\n",
    "            # normalize\n",
    "            inputs_t /= (2*np.max(inputs_t))\n",
    "            points_t /= (2*np.max(points_t))\n",
    "\n",
    "            pc_field_t = {}\n",
    "            pc_field_t[None] = inputs_t\n",
    "            pc_field_t['normals'] = np.zeros((inputs_t.shape[0],1))\n",
    "\n",
    "            pc_field_sub_t = SubsamplePointcloud(inputs_t.shape[0]) #10000, inputs_t.shape[0]\n",
    "            pc_field_t = pc_field_sub_t(pc_field_t)   \n",
    "\n",
    "            points_field_t = {}\n",
    "            points_field_t[None] = points_t\n",
    "            points_field_t['occ'] = points_occ_t\n",
    "            points_field_sub_t = SubsamplePoints(points_occ_t.shape) #2048, points_splits[k].shape[0]\n",
    "            points_field_t = points_field_sub_t(points_field_t)\n",
    "\n",
    "            fields_t = {}\n",
    "            data_t = {}\n",
    "\n",
    "            #for pc_field,points_field in carla_ds:\n",
    "\n",
    "            fields_t['points'] = points_field_t\n",
    "\n",
    "            if pc_field_t is not None:\n",
    "                fields_t['inputs'] = pc_field_t\n",
    "\n",
    "            for field_name_t, field_t in fields_t.items(): \n",
    "\n",
    "                field_data_t = field_t\n",
    "                for k, v in field_data_t.items():\n",
    "                    if k is None:\n",
    "                        data_t[field_name_t] = v\n",
    "                    else:\n",
    "                        data_t['%s.%s' % (field_name_t, k)] = v\n",
    "            points_t = torch.tensor(data_t['points'], device=device)\n",
    "            points_t = points_t[None,:]\n",
    "            inputs_t = torch.tensor(data_t['inputs'], device=device)\n",
    "            inputs_t = inputs_t[None,:]\n",
    "            p_out_t = model(points_t, inputs_t)\n",
    "            occ_hat_t = (p_out_t.probs >= 0.5).cpu().numpy()\n",
    "            occ_hat_t.astype('uint8').tofile(os.path.join(out_dir_ep, str(j).zfill(6) + '.label'))\n",
    "\n",
    "    #                 # sliding windows(1/8 scale):\n",
    "    #                 scale = 8\n",
    "    #                 points_splits = np.array_split(points_t, scale)\n",
    "    #                 occ_hat_t = []\n",
    "    #                 for k in range(scale):\n",
    "    #                     inputs_t = np.fromfile(pc_dir,dtype=np.float32).reshape(-1,4)[:,:3]  \n",
    "\n",
    "    #                     grid_point_mask= np.all(\n",
    "    #                         (inputs_t < max_bound) & (inputs_t >= min_bound), axis=1)\n",
    "    #                     inputs_t = inputs_t[grid_point_mask, :]\n",
    "\n",
    "    #                     # normalize\n",
    "    #                     inputs_t /= (2*np.max(inputs_t))\n",
    "\n",
    "    #                     pc_field_t = {}\n",
    "    #                     pc_field_t[None] = inputs_t\n",
    "    #                     pc_field_t['normals'] = np.zeros((inputs_t.shape[0],1))\n",
    "\n",
    "\n",
    "    #                     pc_field_sub_t = SubsamplePointcloud(inputs_t.shape[0]) #10000\n",
    "    #                     pc_field_t = pc_field_sub_t(pc_field_t)   \n",
    "\n",
    "    #                     points_field_t = {}\n",
    "    #                     points_field_t[None] = points_splits[k]\n",
    "    #                     points_field_t['occ'] = np.zeros((points_splits[k].shape[0],1))\n",
    "    #                     points_field_sub_t = SubsamplePoints(points_splits[k].shape[0]) #2048\n",
    "    #                     points_field_t = points_field_sub_t(points_field_t)\n",
    "\n",
    "    #                     fields_t = {}\n",
    "    #                     data_t = {}\n",
    "\n",
    "    #                     #for pc_field,points_field in carla_ds:\n",
    "\n",
    "    #                     fields_t['points'] = points_field_t\n",
    "\n",
    "    #                     if pc_field_t is not None:\n",
    "    #                         fields_t['inputs'] = pc_field_t\n",
    "\n",
    "    #                     for field_name_t, field_t in fields_t.items(): \n",
    "\n",
    "    #                         field_data_t = field_t\n",
    "    #                         for k, v in field_data_t.items():\n",
    "    #                             if k is None:\n",
    "    #                                 data_t[field_name_t] = v\n",
    "    #                             else:\n",
    "    #                                 data_t['%s.%s' % (field_name_t, k)] = v\n",
    "    #                     points_t = torch.tensor(data_t['points'], device=device)\n",
    "    #                     points_t = points_t[None,:]\n",
    "    #                     inputs_t = torch.tensor(data_t['inputs'], device=device)\n",
    "    #                     inputs_t = inputs_t[None,:]\n",
    "    #                     p_out_t = model(points_t, inputs_t)\n",
    "    #                     occ_hat_t = np.append(occ_hat_t, (p_out_t.probs >= 0.5).cpu().numpy())\n",
    "    #                 occ_hat_t.astype('uint8').tofile(os.path.join(out_dir_ep, str(j).zfill(6) + '.label'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conv_onet] *",
   "language": "python",
   "name": "conda-env-conv_onet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
