{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6953b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.layers import ResnetBlockFC\n",
    "from torch_scatter import scatter_mean, scatter_max\n",
    "from src.common import coordinate2index, normalize_coordinate, normalize_3d_coordinate, map2local\n",
    "from src.encoder.unet import UNet\n",
    "from src.encoder.unet3d import UNet3D\n",
    "\n",
    "\n",
    "class LocalPoolPointnet(nn.Module):\n",
    "    ''' PointNet-based encoder network with ResNet blocks for each point.\n",
    "        Number of input points are fixed.\n",
    "    \n",
    "    Args:\n",
    "        c_dim (int): dimension of latent code c\n",
    "        dim (int): input points dimension\n",
    "        hidden_dim (int): hidden dimension of the network\n",
    "        scatter_type (str): feature aggregation when doing local pooling\n",
    "        unet (bool): weather to use U-Net\n",
    "        unet_kwargs (str): U-Net parameters\n",
    "        unet3d (bool): weather to use 3D U-Net\n",
    "        unet3d_kwargs (str): 3D U-Net parameters\n",
    "        plane_resolution (int): defined resolution for plane feature\n",
    "        grid_resolution (int): defined resolution for grid feature \n",
    "        plane_type (str): feature type, 'xz' - 1-plane, ['xz', 'xy', 'yz'] - 3-plane, ['grid'] - 3D grid volume\n",
    "        padding (float): conventional padding paramter of ONet for unit cube, so [-0.5, 0.5] -> [-0.55, 0.55]\n",
    "        n_blocks (int): number of blocks ResNetBlockFC layers\n",
    "    '''\n",
    "\n",
    "    def __init__(self, c_dim=128, dim=3, hidden_dim=128, scatter_type='max', \n",
    "                 unet=False, unet_kwargs=None, unet3d=False, unet3d_kwargs=None, \n",
    "                 plane_resolution=None, grid_resolution=None, plane_type='xz', padding=0.1, n_blocks=5):\n",
    "        super().__init__()\n",
    "        self.c_dim = c_dim\n",
    "\n",
    "        self.fc_pos = nn.Linear(dim, 2*hidden_dim)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResnetBlockFC(2*hidden_dim, hidden_dim) for i in range(n_blocks)\n",
    "        ])\n",
    "        self.fc_c = nn.Linear(hidden_dim, c_dim)\n",
    "\n",
    "        self.actvn = nn.ReLU()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        if unet:\n",
    "            self.unet = UNet(c_dim, in_channels=c_dim, **unet_kwargs)\n",
    "        else:\n",
    "            self.unet = None\n",
    "\n",
    "        if unet3d:\n",
    "            self.unet3d = UNet3D(**unet3d_kwargs)\n",
    "        else:\n",
    "            self.unet3d = None\n",
    "\n",
    "        self.reso_plane = plane_resolution\n",
    "        self.reso_grid = grid_resolution\n",
    "        self.plane_type = plane_type\n",
    "        self.padding = padding\n",
    "\n",
    "        if scatter_type == 'max':\n",
    "            self.scatter = scatter_max\n",
    "        elif scatter_type == 'mean':\n",
    "            self.scatter = scatter_mean\n",
    "        else:\n",
    "            raise ValueError('incorrect scatter type')\n",
    "\n",
    "\n",
    "    def generate_plane_features(self, p, c, plane='xz'):\n",
    "        # acquire indices of features in plane\n",
    "        xy = normalize_coordinate(p.clone(), plane=plane, padding=self.padding) # normalize to the range of (0, 1)\n",
    "        index = coordinate2index(xy, self.reso_plane)\n",
    "\n",
    "        # scatter plane features from points\n",
    "        fea_plane = c.new_zeros(p.size(0), self.c_dim, self.reso_plane**2)\n",
    "        c = c.permute(0, 2, 1) # B x 512 x T\n",
    "        fea_plane = scatter_mean(c, index, out=fea_plane) # B x 512 x reso^2\n",
    "        fea_plane = fea_plane.reshape(p.size(0), self.c_dim, self.reso_plane, self.reso_plane) # sparce matrix (B x 512 x reso x reso)\n",
    "\n",
    "        # process the plane features with UNet\n",
    "        if self.unet is not None:\n",
    "            fea_plane = self.unet(fea_plane)\n",
    "\n",
    "        return fea_plane\n",
    "\n",
    "    def generate_grid_features(self, p, c):\n",
    "        p_nor = normalize_3d_coordinate(p.clone(), padding=self.padding)\n",
    "        index = coordinate2index(p_nor, self.reso_grid, coord_type='3d')\n",
    "        # scatter grid features from points\n",
    "        fea_grid = c.new_zeros(p.size(0), self.c_dim, self.reso_grid**3)\n",
    "        c = c.permute(0, 2, 1)\n",
    "        fea_grid = scatter_mean(c, index, out=fea_grid) # B x C x reso^3\n",
    "        fea_grid = fea_grid.reshape(p.size(0), self.c_dim, self.reso_grid, self.reso_grid, self.reso_grid) # sparce matrix (B x 512 x reso x reso)\n",
    "\n",
    "        if self.unet3d is not None:\n",
    "            fea_grid = self.unet3d(fea_grid)\n",
    "\n",
    "        return fea_grid\n",
    "\n",
    "    def pool_local(self, xy, index, c):\n",
    "        bs, fea_dim = c.size(0), c.size(2)\n",
    "        keys = xy.keys()\n",
    "\n",
    "        c_out = 0\n",
    "        for key in keys:\n",
    "            # scatter plane features from points\n",
    "            if key == 'grid':\n",
    "                fea = self.scatter(c.permute(0, 2, 1), index[key], dim_size=self.reso_grid**3)\n",
    "            else:\n",
    "                fea = self.scatter(c.permute(0, 2, 1), index[key], dim_size=self.reso_plane**2)\n",
    "            if self.scatter == scatter_max:\n",
    "                fea = fea[0]\n",
    "            # gather feature back to points\n",
    "            fea = fea.gather(dim=2, index=index[key].expand(-1, fea_dim, -1))\n",
    "            c_out += fea\n",
    "        return c_out.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "    def forward(self, p):\n",
    "        batch_size, T, D = p.size()\n",
    "\n",
    "        # acquire the index for each point\n",
    "        coord = {}\n",
    "        index = {}\n",
    "        if 'xz' in self.plane_type:\n",
    "            coord['xz'] = normalize_coordinate(p.clone(), plane='xz', padding=self.padding)\n",
    "            index['xz'] = coordinate2index(coord['xz'], self.reso_plane)\n",
    "        if 'xy' in self.plane_type:\n",
    "            coord['xy'] = normalize_coordinate(p.clone(), plane='xy', padding=self.padding)\n",
    "            index['xy'] = coordinate2index(coord['xy'], self.reso_plane)\n",
    "        if 'yz' in self.plane_type:\n",
    "            coord['yz'] = normalize_coordinate(p.clone(), plane='yz', padding=self.padding)\n",
    "            index['yz'] = coordinate2index(coord['yz'], self.reso_plane)\n",
    "        if 'grid' in self.plane_type:\n",
    "            coord['grid'] = normalize_3d_coordinate(p.clone(), padding=self.padding)\n",
    "            index['grid'] = coordinate2index(coord['grid'], self.reso_grid, coord_type='3d')\n",
    "        \n",
    "        net = self.fc_pos(p)\n",
    "\n",
    "        net = self.blocks[0](net)\n",
    "        for block in self.blocks[1:]:\n",
    "            pooled = self.pool_local(coord, index, net)\n",
    "            net = torch.cat([net, pooled], dim=2)\n",
    "            net = block(net)\n",
    "\n",
    "        c = self.fc_c(net)\n",
    "\n",
    "        fea = {}\n",
    "        if 'grid' in self.plane_type:\n",
    "            fea['grid'] = self.generate_grid_features(p, c)\n",
    "        if 'xz' in self.plane_type:\n",
    "            fea['xz'] = self.generate_plane_features(p, c, plane='xz')\n",
    "        if 'xy' in self.plane_type:\n",
    "            fea['xy'] = self.generate_plane_features(p, c, plane='xy')\n",
    "        if 'yz' in self.plane_type:\n",
    "            fea['yz'] = self.generate_plane_features(p, c, plane='yz')\n",
    "\n",
    "        return fea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c522b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.layers import ResnetBlockFC\n",
    "from src.common import normalize_coordinate, normalize_3d_coordinate, map2local\n",
    "\n",
    "\n",
    "class LocalDecoder(nn.Module):\n",
    "    ''' Decoder.\n",
    "        Instead of conditioning on global features, on plane/volume local features.\n",
    "\n",
    "    Args:\n",
    "        dim (int): input dimension\n",
    "        c_dim (int): dimension of latent conditioned code c\n",
    "        hidden_size (int): hidden size of Decoder network\n",
    "        n_blocks (int): number of blocks ResNetBlockFC layers\n",
    "        leaky (bool): whether to use leaky ReLUs\n",
    "        sample_mode (str): sampling feature strategy, bilinear|nearest\n",
    "        padding (float): conventional padding paramter of ONet for unit cube, so [-0.5, 0.5] -> [-0.55, 0.55]\n",
    "    '''\n",
    "\n",
    "    def __init__(self, dim=3, c_dim=128,\n",
    "                 hidden_size=256, n_blocks=5, leaky=False, sample_mode='bilinear', padding=0.1):\n",
    "        super().__init__()\n",
    "        self.c_dim = c_dim\n",
    "        self.n_blocks = n_blocks\n",
    "\n",
    "        if c_dim != 0:\n",
    "            self.fc_c = nn.ModuleList([\n",
    "                nn.Linear(c_dim, hidden_size) for i in range(n_blocks)\n",
    "            ])\n",
    "\n",
    "\n",
    "        self.fc_p = nn.Linear(dim, hidden_size)\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResnetBlockFC(hidden_size) for i in range(n_blocks)\n",
    "        ])\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        if not leaky:\n",
    "            self.actvn = F.relu\n",
    "        else:\n",
    "            self.actvn = lambda x: F.leaky_relu(x, 0.2)\n",
    "\n",
    "        self.sample_mode = sample_mode\n",
    "        self.padding = padding\n",
    "    \n",
    "\n",
    "    def sample_plane_feature(self, p, c, plane='xz'):\n",
    "        xy = normalize_coordinate(p.clone(), plane=plane, padding=self.padding) # normalize to the range of (0, 1)\n",
    "        xy = xy[:, :, None].float()\n",
    "        vgrid = 2.0 * xy - 1.0 # normalize to (-1, 1)\n",
    "        c = F.grid_sample(c, vgrid, padding_mode='border', align_corners=True, mode=self.sample_mode).squeeze(-1)\n",
    "        return c\n",
    "\n",
    "    def sample_grid_feature(self, p, c):\n",
    "        p_nor = normalize_3d_coordinate(p.clone(), padding=self.padding) # normalize to the range of (0, 1)\n",
    "        p_nor = p_nor[:, :, None, None].float()\n",
    "#         print(np.unique(p.clone().cpu().numpy()),np.unique(p_nor.cpu().numpy()))\n",
    "        vgrid = 2.0 * p_nor - 1.0 # normalize to (-1, 1)\n",
    "        # acutally trilinear interpolation if mode = 'bilinear'\n",
    "        c = F.grid_sample(c, vgrid, padding_mode='border', align_corners=True, mode=self.sample_mode).squeeze(-1).squeeze(-1)\n",
    "        return c\n",
    "\n",
    "\n",
    "    def forward(self, p, c_plane, **kwargs):\n",
    "        if self.c_dim != 0:\n",
    "            plane_type = list(c_plane.keys())\n",
    "            c = 0\n",
    "            if 'grid' in plane_type:\n",
    "                c += self.sample_grid_feature(p, c_plane['grid'])\n",
    "            if 'xz' in plane_type:\n",
    "                c += self.sample_plane_feature(p, c_plane['xz'], plane='xz')\n",
    "            if 'xy' in plane_type:\n",
    "                c += self.sample_plane_feature(p, c_plane['xy'], plane='xy')\n",
    "            if 'yz' in plane_type:\n",
    "                c += self.sample_plane_feature(p, c_plane['yz'], plane='yz')\n",
    "            c = c.transpose(1, 2)\n",
    "\n",
    "        p = p.float()\n",
    "        net = self.fc_p(p)\n",
    "\n",
    "        for i in range(self.n_blocks):\n",
    "            if self.c_dim != 0:\n",
    "                net = net + self.fc_c[i](c)\n",
    "\n",
    "            net = self.blocks[i](net)\n",
    "\n",
    "        out = self.fc_out(self.actvn(net))\n",
    "        out = out.squeeze(-1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c3b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CON\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import distributions as dist\n",
    "# from src.conv_onet.models import decoder\n",
    "\n",
    "\n",
    "class ConvolutionalOccupancyNetwork(nn.Module):\n",
    "    ''' Occupancy Network class.\n",
    "\n",
    "    Args:\n",
    "        decoder (nn.Module): decoder network\n",
    "        encoder (nn.Module): encoder network\n",
    "        device (device): torch device\n",
    "    '''\n",
    "\n",
    "    def __init__(self, decoder, encoder=None, device=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.decoder = decoder.to(device)\n",
    "\n",
    "        if encoder is not None:\n",
    "            self.encoder = encoder.to(device)\n",
    "        else:\n",
    "            self.encoder = None\n",
    "\n",
    "        self._device = device\n",
    "\n",
    "    def forward(self, p, inputs, sample=True, **kwargs):\n",
    "        ''' Performs a forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            p (tensor): sampled points\n",
    "            inputs (tensor): conditioning input\n",
    "            sample (bool): whether to sample for z\n",
    "        '''\n",
    "        #############\n",
    "        if isinstance(p, dict):\n",
    "            batch_size = p['p'].size(0)\n",
    "        else:\n",
    "            batch_size = p.size(0)\n",
    "        c = self.encode_inputs(inputs)\n",
    "        p_r = self.decode(p, c, **kwargs)\n",
    "        return p_r\n",
    "\n",
    "    def encode_inputs(self, inputs):\n",
    "        ''' Encodes the input.\n",
    "\n",
    "        Args:\n",
    "            input (tensor): the input\n",
    "        '''\n",
    "\n",
    "        if self.encoder is not None:\n",
    "            c = self.encoder(inputs)\n",
    "        else:\n",
    "            # Return inputs?\n",
    "            c = torch.empty(inputs.size(0), 0)\n",
    "\n",
    "        return c\n",
    "\n",
    "    def decode(self, p, c, **kwargs):\n",
    "        ''' Returns occupancy probabilities for the sampled points.\n",
    "\n",
    "        Args:\n",
    "            p (tensor): points\n",
    "            c (tensor): latent conditioned code c\n",
    "        '''\n",
    "\n",
    "        logits = self.decoder(p, c, **kwargs)\n",
    "        p_r = dist.Bernoulli(logits=logits)\n",
    "        return p_r\n",
    "\n",
    "    def to(self, device):\n",
    "        ''' Puts the model to the device.\n",
    "\n",
    "        Args:\n",
    "            device (device): pytorch device\n",
    "        '''\n",
    "        model = super().to(device)\n",
    "        model._device = device\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30a3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsamplePointcloud(object):\n",
    "    ''' Point cloud subsampling transformation class.\n",
    "\n",
    "    It subsamples the point cloud data.\n",
    "\n",
    "    Args:\n",
    "        N (int): number of points to be subsampled\n",
    "    '''\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "\n",
    "    def __call__(self, data):\n",
    "        ''' Calls the transformation.\n",
    "\n",
    "        Args:\n",
    "            data (dict): data dictionary\n",
    "        '''\n",
    "        data_out = data.copy()\n",
    "        points = data[None]\n",
    "        normals = data['normals']\n",
    "\n",
    "        indices = np.random.randint(points.shape[0], size=self.N)\n",
    "        data_out[None] = points[indices, :]\n",
    "        data_out['normals'] = normals[indices, :]\n",
    "\n",
    "        return data_out\n",
    "    \n",
    "    \n",
    "class SubsamplePoints(object):\n",
    "    ''' Points subsampling transformation class.\n",
    "\n",
    "    It subsamples the points data.\n",
    "\n",
    "    Args:\n",
    "        N (int): number of points to be subsampled\n",
    "    '''\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "\n",
    "    def __call__(self, data):\n",
    "        ''' Calls the transformation.\n",
    "\n",
    "        Args:\n",
    "            data (dictionary): data dictionary\n",
    "        '''\n",
    "\n",
    "        points = data[None]\n",
    "        occ = data['occ']\n",
    "\n",
    "        data_out = data.copy()\n",
    "        if isinstance(self.N, int):\n",
    "            idx = np.random.randint(points.shape[0], size=self.N)\n",
    "            data_out.update({\n",
    "                None: points[idx, :],\n",
    "                'occ':  occ[idx],\n",
    "            })\n",
    "#         else:\n",
    "#             Nt_out, Nt_in = self.N\n",
    "#             occ_binary = (occ >= 0.5)\n",
    "#             points0 = points[~occ_binary]\n",
    "#             points1 = points[occ_binary]\n",
    "\n",
    "#             idx0 = np.random.randint(points0.shape[0], size=Nt_out)\n",
    "#             idx1 = np.random.randint(points1.shape[0], size=Nt_in)\n",
    "\n",
    "#             points0 = points0[idx0, :]\n",
    "#             points1 = points1[idx1, :]\n",
    "#             points = np.concatenate([points0, points1], axis=0)\n",
    "\n",
    "#             occ0 = np.zeros(Nt_out, dtype=np.float32)\n",
    "#             occ1 = np.ones(Nt_in, dtype=np.float32)\n",
    "#             occ = np.concatenate([occ0, occ1], axis=0)\n",
    "\n",
    "#             volume = occ_binary.sum() / len(occ_binary)\n",
    "#             volume = volume.astype(np.float32)\n",
    "\n",
    "#             data_out.update({\n",
    "#                 None: points,\n",
    "#                 'occ': occ,\n",
    "#                 'volume': volume,\n",
    "#             })\n",
    "        return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0085b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carla Dataloader \n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import random\n",
    "# import json\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset\n",
    "# from torch.utils import data\n",
    "\n",
    "# class CarlaDataset(Dataset):\n",
    "#     \"\"\"Carla Simulation Dataset for 3D mapping project\n",
    "    \n",
    "#     Access to the processed data, including evaluation labels predictions velodyne poses times\n",
    "#     \"\"\"\n",
    "#     def __init__(self, directory,\n",
    "#         device='cuda',\n",
    "#         num_frames=1,\n",
    "#         voxelize_input=False,\n",
    "#         binary_counts=True,\n",
    "#         random_flips=False,       \n",
    "#         ):\n",
    "#         '''Constructor.\n",
    "#         Parameters:\n",
    "#             directory: directory to the dataset\n",
    "#         '''\n",
    "\n",
    "#         self.voxelize_input = voxelize_input\n",
    "#         self.binary_counts = binary_counts\n",
    "#         self._directory = directory\n",
    "#         self._num_frames = num_frames\n",
    "#         self.device = device\n",
    "#         self.random_flips = random_flips\n",
    "        \n",
    "#         self._scenes = sorted(os.listdir(self._directory))\n",
    "#         self._scenes = [os.path.join(scene, \"cartesian\") for scene in self._scenes]\n",
    "\n",
    "#         self._num_scenes = len(self._scenes)\n",
    "#         self._num_frames_scene = []\n",
    "\n",
    "#         self._velodyne_list = []\n",
    "#         self._eval_labels = []\n",
    "#         self._frames_list = []\n",
    "\n",
    "#         for scene in self._scenes:\n",
    "#             velodyne_dir = os.path.join(self._directory, scene, 'pointcloud')\n",
    "#             eval_dir = os.path.join(self._directory, scene, 'points')\n",
    "#             self._num_frames_scene.append(len(os.listdir(velodyne_dir)))\n",
    "            \n",
    "#             frames_list = [os.path.splitext(filename)[0] for filename in sorted(os.listdir(velodyne_dir))]\n",
    "#             self._frames_list.extend(frames_list)\n",
    "\n",
    "#             self._velodyne_list.extend([os.path.join(velodyne_dir, 'pointcloud_' + str(frame).zfill(6) +'.npz') for frame in range(len(frames_list))])\n",
    "#             self._eval_labels.extend([os.path.join(eval_dir, 'points_' + str(frame).zfill(6) +'.npz') for frame in range(len(frames_list))])\n",
    "\n",
    "#         self._cum_num_frames = np.cumsum(np.array(self._num_frames_scene) - self._num_frames + 1)\n",
    "#     # Use all frames, if there is no data then zero pad\n",
    "#     def __len__(self):\n",
    "#         return sum(self._num_frames_scene)\n",
    "    \n",
    "#     def collate_fn(self, batch):\n",
    "#         #input_batch = [bi[0] for bi in data]\n",
    "# #         output_batch = [bi[1] for bi in data]\n",
    "#         #return input_batch\n",
    "        \n",
    "#         batch = list(filter(lambda x: x is not None, batch))\n",
    "#         return data.dataloader.default_collate(batch)\n",
    "\n",
    "#     def get_file_path(self, idx):\n",
    "#         print(self._frames_list[idx])\n",
    "\n",
    "        \n",
    "#     def __getitem__(self, idx):\n",
    "\n",
    "#         pointcloud = np.load(self._velodyne_list[idx])\n",
    "#         points = np.load(self._eval_labels[idx])\n",
    "        \n",
    "#         pc_field = {}\n",
    "#         pc_field[None] = pointcloud['points']\n",
    "#         pc_field['normals'] = pointcloud['normals']\n",
    "        \n",
    "#         pc_field_sub = SubsamplePointcloud(10000)\n",
    "#         pc_field = pc_field_sub(pc_field)\n",
    "        \n",
    "#         points_field = {}\n",
    "#         points_field[None] = points['points']\n",
    "#         points_field['occ'] = points['occupancies']\n",
    "        \n",
    "#         points_field_sub = SubsamplePoints(2048)\n",
    "#         points_field = points_field_sub(points_field)\n",
    "        \n",
    "# #         print(pc_field[None].shape, pc_field['normals'].shape)\n",
    "# #         print(points_field[None].shape, points_field['occupancies'].shape)\n",
    "        \n",
    "#         fields = {}\n",
    "#         data = {}\n",
    "        \n",
    "#         #for pc_field,points_field in carla_ds:\n",
    "\n",
    "#         fields['points'] = points_field\n",
    "        \n",
    "#         if pc_field is not None:\n",
    "#             fields['inputs'] = pc_field\n",
    "\n",
    "#         for field_name, field in fields.items():\n",
    "#             field_data = field\n",
    "#             for k, v in field_data.items():\n",
    "#                 if k is None:\n",
    "#                     data[field_name] = v\n",
    "#                 else:\n",
    "#                     data['%s.%s' % (field_name, k)] = v\n",
    "# #         print(data['points'].shape, data['points.occ'].shape, data['inputs'].shape)\n",
    "#         return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6baab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(compressed):\n",
    "    ''' given a bit encoded voxel grid, make a normal voxel grid out of it.  '''\n",
    "    uncompressed = np.zeros(compressed.shape[0] * 8, dtype=np.uint8)\n",
    "    uncompressed[::8] = compressed[:] >> 7 & 1\n",
    "    uncompressed[1::8] = compressed[:] >> 6 & 1\n",
    "    uncompressed[2::8] = compressed[:] >> 5 & 1\n",
    "    uncompressed[3::8] = compressed[:] >> 4 & 1\n",
    "    uncompressed[4::8] = compressed[:] >> 3 & 1\n",
    "    uncompressed[5::8] = compressed[:] >> 2 & 1\n",
    "    uncompressed[6::8] = compressed[:] >> 1 & 1\n",
    "    uncompressed[7::8] = compressed[:] & 1\n",
    "\n",
    "    return uncompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7dfad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rellis3d dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils import data\n",
    "\n",
    "class RellisDataset(Dataset):\n",
    "    \"\"\"Rellis3D Dataset for convOccn\n",
    "    \n",
    "    Access to the processed data, including evaluation labels predictions velodyne poses times\n",
    "    \"\"\"\n",
    "    def __init__(self, directory,\n",
    "        device='cuda',\n",
    "        num_frames=1,\n",
    "        voxelize_input=False,\n",
    "        binary_counts=True,\n",
    "        random_flips=False,   \n",
    "        model_setting = 'train'\n",
    "        ):\n",
    "        '''Constructor.\n",
    "        Parameters:\n",
    "            directory: directory to the dataset\n",
    "        '''\n",
    "\n",
    "        self.voxelize_input = voxelize_input\n",
    "        self.binary_counts = binary_counts\n",
    "        self._directory = directory\n",
    "        self._num_frames = num_frames\n",
    "        self.device = device\n",
    "        self.random_flips = random_flips\n",
    "        \n",
    "        self._scenes = sorted(os.listdir(self._directory))\n",
    "#         self._scenes = [os.path.join(scene, \"cartesian\") for scene in self._scenes]\n",
    "\n",
    "        self._num_scenes = len(self._scenes)\n",
    "        #self._num_frames_scene = []\n",
    "        self._num_frames_scene = 0\n",
    "        \n",
    "        self._velodyne_list = []\n",
    "        self._eval_labels = []\n",
    "        self._frames_list = []\n",
    "        \n",
    "        split_dir = os.path.join(self._directory, \"pt_\"+model_setting+\".lst\")\n",
    "\n",
    "        # Generate list of scenes and indices to iterate over\n",
    "        self._scenes_list = []\n",
    "        self._index_list = []\n",
    "\n",
    "        with open(split_dir, 'r') as split_file:\n",
    "            for line in split_file:\n",
    "                image_path = line.split(' ')\n",
    "                image_path_lst = image_path[0].split('/')\n",
    "                scene_num = image_path_lst[0]\n",
    "                frame_index = int(image_path_lst[2][0:6])\n",
    "                self._scenes_list.append(scene_num)\n",
    "                self._index_list.append(frame_index)\n",
    "\n",
    "        for i in range(len(self._scenes_list)):\n",
    "            velodyne_dir = os.path.join(self._directory, self._scenes_list[i], 'velodyne')\n",
    "            eval_dir = os.path.join(self._directory, self._scenes_list[i], 'voxels')\n",
    "            self._num_frames_scene += 1\n",
    "            \n",
    "            self._velodyne_list.extend([os.path.join(velodyne_dir, str(self._index_list[i]).zfill(6) + '.bin')])\n",
    "            self._eval_labels.extend([os.path.join(eval_dir, str(self._index_list[i]).zfill(6) + '.label')])\n",
    "        \n",
    "#             velodyne_dir = os.path.join(self._directory, scene, 'velodyne')\n",
    "#             eval_dir = os.path.join(self._directory, scene, 'voxels')\n",
    "#             self._num_frames_scene.append(len(os.listdir(velodyne_dir)))\n",
    "            \n",
    "#             frames_list = [os.path.splitext(filename)[0] for filename in sorted(os.listdir(velodyne_dir))]\n",
    "#             self._frames_list.extend(frames_list)\n",
    "\n",
    "#             self._velodyne_list.extend([os.path.join(velodyne_dir, str(frame).zfill(6) +'.bin') for frame in range(len(frames_list))])\n",
    "#             self._eval_labels.extend([os.path.join(eval_dir, str(frame).zfill(6) +'.label') for frame in range(len(frames_list))])\n",
    "\n",
    "#         self._cum_num_frames = np.cumsum(np.array(self._num_frames_scene) - self._num_frames + 1)\n",
    "\n",
    "    # Use all frames, if there is no data then zero pad\n",
    "    def __len__(self):\n",
    "#         return sum(self._num_frames_scene)\n",
    "        return self._num_frames_scene\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        batch = list(filter(lambda x: x is not None, batch))\n",
    "        return data.dataloader.default_collate(batch)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        pointcloud = np.fromfile(self._velodyne_list[idx],dtype=np.float32).reshape(-1,4)[:,:3]\n",
    "\n",
    "        \n",
    "        points_occ = np.fromfile(self._eval_labels[idx], dtype=np.uint8)\n",
    "        \n",
    "        mask = points_occ != 0\n",
    "        points_occ = points_occ[mask]\n",
    "#         print(np.unique(points_occ, return_counts=True))\n",
    "        \n",
    "        # points\n",
    "        min_bound = [-25.6, -25.6, -2]\n",
    "        max_bound = [25.6, 25.6, 1.2]\n",
    "        grid_size = [256, 256, 16]\n",
    "        coor_ranges = min_bound + max_bound\n",
    "        voxel_sizes = [abs(coor_ranges[3] - coor_ranges[0]) / grid_size[0], \n",
    "                    abs(coor_ranges[4] - coor_ranges[1]) / grid_size[1],\n",
    "                    abs(coor_ranges[5] - coor_ranges[2]) / grid_size[2]]\n",
    "\n",
    "        x = np.linspace(min_bound[0], max_bound[0], num=int(grid_size[0])) + voxel_sizes[0] / 2\n",
    "        y = np.linspace(min_bound[1], max_bound[1], num=int(grid_size[1])) + voxel_sizes[1] / 2\n",
    "        z = np.linspace(min_bound[2], max_bound[2], num=int(grid_size[2])) + voxel_sizes[2] / 2\n",
    "        xv, yv, zv = np.meshgrid(x, y, z, indexing=\"ij\")\n",
    "\n",
    "        points = np.stack((xv, yv, zv))\n",
    "        points = np.moveaxis(points,0,-1).reshape(-1,3)\n",
    "        points = points[mask]\n",
    "        \n",
    "        # Filter points outside of voxel grid\n",
    "        grid_point_mask= np.all(\n",
    "            (pointcloud < max_bound) & (pointcloud >= min_bound), axis=1)\n",
    "        pointcloud = pointcloud[grid_point_mask, :]\n",
    "        \n",
    "        # normalize\n",
    "        pointcloud /= (2*np.max(pointcloud))\n",
    "        points /= (2*np.max(points))\n",
    "#         print('nm:',np.unique(pointcloud, return_counts=True))\n",
    "#         print('p:',np.unique(pointcloud, return_counts=True))\n",
    "        \n",
    "#         pocc_t = copy.deepcopy(points_occ)\n",
    "        \n",
    "#         points_occ[pocc_t != 40] = 1\n",
    "#         points_occ[pocc_t == 40] = 0\n",
    "        points_occ[points_occ == 40] = 0\n",
    "        points_occ[points_occ != 0 ] = 1\n",
    "                \n",
    "        pc_field = {}\n",
    "        pc_field[None] = pointcloud\n",
    "        pc_field['normals'] = np.zeros((pointcloud.shape[0],1))\n",
    "    \n",
    "        pc_field_sub = SubsamplePointcloud(10000) #10000, 131072\n",
    "        pc_field = pc_field_sub(pc_field)\n",
    "        \n",
    "\n",
    "        # normalize points\n",
    "        \n",
    "        points_field = {}\n",
    "        points_field[None] = points\n",
    "        points_field['occ'] = points_occ\n",
    "        \n",
    "        points_field_sub = SubsamplePoints(2048) #2048, 131072\n",
    "        points_field = points_field_sub(points_field)\n",
    "        \n",
    "    #         print(pc_field[None].shape, pc_field['normals'].shape)\n",
    "    #         print(points_field[None].shape, points_field['occupancies'].shape)\n",
    "        \n",
    "        fields = {}\n",
    "        data = {}\n",
    "        \n",
    "        #for pc_field,points_field in carla_ds:\n",
    "\n",
    "        fields['points'] = points_field\n",
    "        \n",
    "        if pc_field is not None:\n",
    "            fields['inputs'] = pc_field\n",
    "\n",
    "        for field_name, field in fields.items():\n",
    "            field_data = field\n",
    "            for k, v in field_data.items():\n",
    "                if k is None:\n",
    "                    data[field_name] = v\n",
    "                else:\n",
    "                    data['%s.%s' % (field_name, k)] = v\n",
    "#         print(data['points'].shape, data['points.occ'].shape, data['inputs'].shape)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95c7bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "r3d_dir = \"/home/jason/rellis3d\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "carla_ds_train = RellisDataset(directory=r3d_dir, device=device, model_setting='train')\n",
    "carla_ds_eval = RellisDataset(directory=r3d_dir, device=device, model_setting='val')\n",
    "\n",
    "dataloader_train = DataLoader(carla_ds_train, batch_size=4, shuffle=True, collate_fn=carla_ds_train.collate_fn, num_workers=4)\n",
    "dataloader_eval = DataLoader(carla_ds_eval, batch_size=1, shuffle=False, collate_fn=carla_ds_eval.collate_fn, num_workers=4)\n",
    "# o1= next(iter(Dataloader))\n",
    "#print(list(o1[0].keys()), list(o2[0].keys()))\n",
    "# test = o2[0]\n",
    "# nz = np.sum(test!=0)\n",
    "# print(o2[0].shape, nz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bc74826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalOccupancyNetwork(\n",
      "  (decoder): LocalDecoder(\n",
      "    (fc_c): ModuleList(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (fc_p): Linear(in_features=3, out_features=32, bias=True)\n",
      "    (blocks): ModuleList(\n",
      "      (0): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "      )\n",
      "      (1): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "      )\n",
      "      (2): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "      )\n",
      "      (3): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "      )\n",
      "      (4): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (fc_out): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      "  (encoder): LocalPoolPointnet(\n",
      "    (fc_pos): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (blocks): ModuleList(\n",
      "      (0): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "        (shortcut): Linear(in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "      (1): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "        (shortcut): Linear(in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "      (2): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "        (shortcut): Linear(in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "      (3): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "        (shortcut): Linear(in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "      (4): ResnetBlockFC(\n",
      "        (fc_0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (fc_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (actvn): ReLU()\n",
      "        (shortcut): Linear(in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (fc_c): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (actvn): ReLU()\n",
      "    (unet3d): UNet3D(\n",
      "      (encoders): ModuleList(\n",
      "        (0): Encoder(\n",
      "          (basic_module): DoubleConv(\n",
      "            (SingleConv1): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "            (SingleConv2): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Encoder(\n",
      "          (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "          (basic_module): DoubleConv(\n",
      "            (SingleConv1): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "            (SingleConv2): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Encoder(\n",
      "          (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "          (basic_module): DoubleConv(\n",
      "            (SingleConv1): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "            (SingleConv2): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): Encoder(\n",
      "          (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "          (basic_module): DoubleConv(\n",
      "            (SingleConv1): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "            (SingleConv2): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoders): ModuleList(\n",
      "        (0): Decoder(\n",
      "          (upsampling): Upsampling()\n",
      "          (basic_module): DoubleConv(\n",
      "            (SingleConv1): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "            (SingleConv2): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Decoder(\n",
      "          (upsampling): Upsampling()\n",
      "          (basic_module): DoubleConv(\n",
      "            (SingleConv1): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "            (SingleConv2): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Decoder(\n",
      "          (upsampling): Upsampling()\n",
      "          (basic_module): DoubleConv(\n",
      "            (SingleConv1): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "            (SingleConv2): SingleConv(\n",
      "              (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (ReLU): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_conv): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (final_activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model (configs/pointcloud/room_grid32.yaml)\n",
    "# src.conv_onet.config.py get_model\n",
    "\n",
    "encoder_kwargs = {'hidden_dim': 32,\n",
    "                  'plane_type': 'grid',\n",
    "                  'grid_resolution': 64, #32\n",
    "                  'unet3d': True,\n",
    "                  'unet3d_kwargs': {\n",
    "                    'num_levels': 4,#3\n",
    "                    'f_maps': 32,\n",
    "                    'in_channels': 32,\n",
    "                    'out_channels': 32}}\n",
    "\n",
    "decoder_kwargs = {\n",
    "    'sample_mode': 'bilinear', # bilinear / nearest\n",
    "    'hidden_size': 32 }\n",
    "\n",
    "c_dim = 32\n",
    "dim = 3\n",
    "padding = 0.1\n",
    "decoder = LocalDecoder(dim=dim, c_dim=c_dim, padding=padding,\n",
    "        **decoder_kwargs)\n",
    "\n",
    "encoder = LocalPoolPointnet(dim=dim, c_dim=c_dim, padding=padding,\n",
    "            **encoder_kwargs)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ConvolutionalOccupancyNetwork(\n",
    "        decoder, encoder, device=device\n",
    "    )\n",
    "\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc8539c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loss \n",
    "\n",
    "def compute_loss(data):\n",
    "    ''' Computes the loss.\n",
    "\n",
    "    Args:\n",
    "        data (dict): data dictionary\n",
    "    '''    \n",
    "    p = data.get('points').to(device)\n",
    "    occ = data.get('points.occ').to(device)\n",
    "    inputs = data.get('inputs', torch.empty(p.size(0), 0)).to(device)\n",
    "\n",
    "    if 'pointcloud_crop' in data.keys():\n",
    "        # add pre-computed index\n",
    "        inputs = add_key(inputs, data.get('inputs.ind'), 'points', 'index', device=device)\n",
    "        inputs['mask'] = data.get('inputs.mask').to(device)\n",
    "        # add pre-computed normalized coordinates\n",
    "        p = add_key(p, data.get('points.normalized'), 'p', 'p_n', device=device)\n",
    "\n",
    "    c = model.encode_inputs(inputs)\n",
    "\n",
    "    kwargs = {}\n",
    "    # General points\n",
    "    logits = model.decode(p, c, **kwargs).logits\n",
    "    loss_i = F.binary_cross_entropy_with_logits(\n",
    "        logits, occ.float(), reduction='none')\n",
    "    loss = loss_i.sum(-1).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b87fc58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute iou\n",
    "def compute_iou(occ1, occ2):\n",
    "    ''' Computes the Intersection over Union (IoU) value for two sets of\n",
    "    occupancy values.\n",
    "\n",
    "    Args:\n",
    "        occ1 (tensor): first set of occupancy values\n",
    "        occ2 (tensor): second set of occupancy values\n",
    "    '''\n",
    "    occ1 = np.asarray(occ1)\n",
    "    occ2 = np.asarray(occ2)\n",
    "\n",
    "    # Put all data in second dimension\n",
    "    # Also works for 1-dimensional data\n",
    "    if occ1.ndim >= 2:\n",
    "        occ1 = occ1.reshape(occ1.shape[0], -1)\n",
    "    if occ2.ndim >= 2:\n",
    "        occ2 = occ2.reshape(occ2.shape[0], -1)\n",
    "\n",
    "    # Convert to boolean values\n",
    "    occ1 = (occ1 >= 0.5)\n",
    "    occ2 = (occ2 >= 0.5)\n",
    "\n",
    "    # Compute IOU\n",
    "    area_union = (occ1 | occ2).astype(np.float32).sum(axis=-1)\n",
    "    area_intersect = (occ1 & occ2).astype(np.float32).sum(axis=-1)\n",
    "    \n",
    "    print(area_union, area_intersect)\n",
    "\n",
    "    iou = (area_intersect / area_union)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def eval_step(data):\n",
    "    model.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147b2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Intersection, union for one frame\n",
    "def iou_one_frame(pred, target, n_classes=23):\n",
    "    pred = np.asarray(pred)\n",
    "    target = np.asarray(target)\n",
    "    pred = pred.reshape(-1)\n",
    "    target = target.reshape(-1)\n",
    "    intersection = np.zeros(n_classes)\n",
    "    union = np.zeros(n_classes)\n",
    "\n",
    "    for cls in range(n_classes):\n",
    "        pred_inds = pred == cls\n",
    "        target_inds = target == cls\n",
    "        intersection[cls] = (pred_inds[target_inds]).sum() # Cast to long to prevent overflows\n",
    "        union[cls] = pred_inds.sum() + target_inds.sum() - intersection[cls]\n",
    "    return intersection, union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca08fa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] it=050, loss=495.1362, acc=0.92, iou=0.47\n",
      "[Epoch 00] it=100, loss=406.9232, acc=0.93, iou=0.52\n",
      "[Epoch 00] it=150, loss=391.6013, acc=0.93, iou=0.54\n",
      "[Epoch 00] it=200, loss=388.1500, acc=0.93, iou=0.55\n",
      "[Epoch 00] it=250, loss=370.9835, acc=0.94, iou=0.56\n",
      "[Epoch 00] it=300, loss=386.4887, acc=0.93, iou=0.55\n",
      "[Epoch 00] it=350, loss=382.3016, acc=0.93, iou=0.56\n",
      "[Epoch 00] it=400, loss=365.4266, acc=0.94, iou=0.57\n",
      "[Epoch 00] it=450, loss=368.8153, acc=0.94, iou=0.57\n",
      "[Epoch 00] it=500, loss=362.9131, acc=0.94, iou=0.58\n",
      "[Epoch 00] it=550, loss=366.4593, acc=0.93, iou=0.58\n",
      "[Epoch 00] it=600, loss=360.9328, acc=0.94, iou=0.58\n",
      "[Epoch 00] it=650, loss=351.7759, acc=0.94, iou=0.59\n",
      "[Epoch 00] it=700, loss=353.8149, acc=0.94, iou=0.58\n",
      "[Epoch 00] it=750, loss=347.7660, acc=0.94, iou=0.58\n",
      "[Epoch 00] it=800, loss=360.0291, acc=0.94, iou=0.58\n",
      "[Epoch 00] it=850, loss=351.3802, acc=0.94, iou=0.59\n",
      "[Epoch 00] it=900, loss=347.0738, acc=0.94, iou=0.59\n",
      "[Epoch 00] it=950, loss=359.0088, acc=0.94, iou=0.59\n",
      "[Epoch 00] it=1000, loss=348.7187, acc=0.94, iou=0.59\n",
      "[Epoch 00] it=1050, loss=346.4085, acc=0.94, iou=0.59\n",
      "[Epoch 00] it=1100, loss=346.0882, acc=0.94, iou=0.59\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14045/2555543178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mloss_kt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                    maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv_onet/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import shutil\n",
    "\n",
    "save_dir = '/home/jason/convolutional_occupancy_networks/out/r3d/'\n",
    "write_dir = '/home/jason/convolutional_occupancy_networks/out/r3d_sw/'\n",
    "writer = SummaryWriter(write_dir)\n",
    "seed = 42\n",
    "# setup_seed(seed)\n",
    "lr = 0.001\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "decayRate = 0.96\n",
    "epoch_num = 10000\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(BETA1, BETA2))\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "device = 'cuda'\n",
    "print_every = 50\n",
    "\n",
    "it = 0\n",
    "loss_kt = 0\n",
    "iou_kt = 0\n",
    "acc_kt = 0\n",
    "best_iou = 0\n",
    "\n",
    "velo_dir = '/home/jason/rellis3d/00000/velodyne'\n",
    "output_dir = '/home/jason/convolutional_occupancy_networks/out/r3d_scene0/'\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "    \n",
    "if os.path.exists(save_dir):\n",
    "    shutil.rmtree(save_dir)\n",
    "    \n",
    "if os.path.exists(write_dir):\n",
    "    shutil.rmtree(write_dir)\n",
    "\n",
    "os.mkdir(output_dir)\n",
    "os.mkdir(save_dir)\n",
    "os.mkdir(write_dir)\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "\n",
    "    model.train()\n",
    "    for batch in dataloader_train:\n",
    "\n",
    "        it += 1\n",
    "\n",
    "        # Training\n",
    "        optimizer.zero_grad()\n",
    "        loss = compute_loss(batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_kt += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # acc\n",
    "            points = batch['points'].to(device)\n",
    "            points_occ = batch['points.occ'].to(device)\n",
    "            inputs = batch['inputs'].to(device)\n",
    "            \n",
    "            p_out = model(points, inputs)\n",
    "\n",
    "            occ = (points_occ >= 0.5).cpu().numpy()\n",
    "            occ_hat = (p_out.probs >= 0.5).cpu().numpy()\n",
    "            acc = np.sum(occ == occ_hat, axis = 1) / occ.shape[1]\n",
    "\n",
    "            intersection, union = iou_one_frame(occ, occ_hat, 2)\n",
    "            mIou = np.mean(intersection / union)\n",
    "            iou_kt += mIou\n",
    "\n",
    "            acc_batch = np.mean(acc)\n",
    "            acc_kt += acc_batch\n",
    "            \n",
    "            # Record\n",
    "            writer.add_scalar('/Loss/Train', loss.item(), it)\n",
    "            writer.add_scalar('/Accuracy/Train', acc_batch, it)\n",
    "            writer.add_scalar('/mIoU/Train', mIou, it)\n",
    "                \n",
    "        if it % print_every == 0 :\n",
    "            print(\"[Epoch %02d] it=%03d, loss=%.4f, acc=%.2f, iou=%.2f\" % (epoch, it,loss_kt/print_every, acc_kt/print_every, iou_kt/print_every))\n",
    "            loss_kt = 0\n",
    "            iou_kt = 0\n",
    "            acc_kt = 0\n",
    "        \n",
    "        \n",
    "    my_lr_scheduler.step()\n",
    "    \n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    acc_batches = 0\n",
    "    iou = 0\n",
    "    with torch.no_grad():\n",
    "        for bt in dataloader_eval:\n",
    "            points = bt['points'].to(device)\n",
    "            points_occ = bt['points.occ'].to(device)\n",
    "            inputs = bt['inputs'].to(device)\n",
    "\n",
    "            p_out = model(points, inputs)\n",
    "\n",
    "            occ = (points_occ >= 0.5).cpu().numpy()\n",
    "            occ_hat = (p_out.probs >= 0.5).cpu().numpy()\n",
    "            acc = np.sum(occ == occ_hat, axis = 1) / occ.shape[1]\n",
    "            acc_batch = np.mean(acc)        \n",
    "            acc_batches += acc_batch\n",
    "            \n",
    "            intersection, union = iou_one_frame(occ, occ_hat, 2)\n",
    "            mIou = np.mean(intersection/union)\n",
    "            iou += mIou\n",
    "            \n",
    "            # Record\n",
    "            writer.add_scalar('/Accuracy/Val', acc_batch, it)\n",
    "            writer.add_scalar('/mIoU/Val', mIou, it)\n",
    "\n",
    "    acc_batches /= len(dataloader_eval)\n",
    "    iou /= len(dataloader_eval)\n",
    "    print(\"acc_eval:%.2f, iou_eval:%.2f\" % (acc_batches, iou))\n",
    "    \n",
    "    \n",
    "    if iou >= best_iou:\n",
    "        best_iou = iou\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"Epoch\" + str(epoch) + \".pt\"))\n",
    "        \n",
    "        # Generate output        \n",
    "        \n",
    "        # use frame 100 - 150:\n",
    "        with torch.no_grad():\n",
    "\n",
    "            out_dir_ep = os.path.join(output_dir, \"Epoch\" + str(epoch))\n",
    "\n",
    "            if not os.path.exists(out_dir_ep):\n",
    "                os.mkdir(out_dir_ep)\n",
    "\n",
    "            for j in range(100,150):\n",
    "                # points\n",
    "                min_bound = [-25.6, -25.6, -2]\n",
    "                max_bound = [25.6, 25.6, 1.2]\n",
    "                grid_size = [256, 256, 16]\n",
    "                coor_ranges = min_bound + max_bound\n",
    "                voxel_sizes = [abs(coor_ranges[3] - coor_ranges[0]) / grid_size[0], \n",
    "                            abs(coor_ranges[4] - coor_ranges[1]) / grid_size[1],\n",
    "                            abs(coor_ranges[5] - coor_ranges[2]) / grid_size[2]]\n",
    "\n",
    "                x = np.linspace(min_bound[0], max_bound[0], num=int(grid_size[0])) + voxel_sizes[0] / 2\n",
    "                y = np.linspace(min_bound[1], max_bound[1], num=int(grid_size[1])) + voxel_sizes[1] / 2\n",
    "                z = np.linspace(min_bound[2], max_bound[2], num=int(grid_size[2])) + voxel_sizes[2] / 2\n",
    "                xv, yv, zv = np.meshgrid(x, y, z, indexing=\"ij\")\n",
    "\n",
    "                points_t = np.stack((xv, yv, zv))\n",
    "                points_t = np.moveaxis(points_t,0,-1).reshape(-1,3)\n",
    "                points_t /= (2*np.max(points_t))\n",
    "\n",
    "                pc_dir = os.path.join(velo_dir, str(j).zfill(6) + '.bin')\n",
    "\n",
    "                # sliding windows(1/8 scale):\n",
    "                scale = 8\n",
    "                points_splits = np.array_split(points_t, scale)\n",
    "                occ_hat_t = []\n",
    "                for k in range(scale):\n",
    "                    inputs_t = np.fromfile(pc_dir,dtype=np.float32).reshape(-1,4)[:,:3]  \n",
    "                    \n",
    "                    grid_point_mask= np.all(\n",
    "                        (inputs_t < max_bound) & (inputs_t >= min_bound), axis=1)\n",
    "                    inputs_t = inputs_t[grid_point_mask, :]\n",
    "                    \n",
    "                    # normalize\n",
    "                    inputs_t /= (2*np.max(inputs_t))\n",
    "\n",
    "                    pc_field_t = {}\n",
    "                    pc_field_t[None] = inputs_t\n",
    "                    pc_field_t['normals'] = np.zeros((inputs_t.shape[0],1))\n",
    "\n",
    "\n",
    "                    pc_field_sub_t = SubsamplePointcloud(inputs_t.shape[0]) #10000\n",
    "                    pc_field_t = pc_field_sub_t(pc_field_t)   \n",
    "\n",
    "                    points_field_t = {}\n",
    "                    points_field_t[None] = points_splits[k]\n",
    "                    points_field_t['occ'] = np.zeros((points_splits[k].shape[0],1))\n",
    "                    points_field_sub_t = SubsamplePoints(points_splits[k].shape[0]) #2048\n",
    "                    points_field_t = points_field_sub_t(points_field_t)\n",
    "\n",
    "                    fields_t = {}\n",
    "                    data_t = {}\n",
    "\n",
    "                    #for pc_field,points_field in carla_ds:\n",
    "\n",
    "                    fields_t['points'] = points_field_t\n",
    "\n",
    "                    if pc_field_t is not None:\n",
    "                        fields_t['inputs'] = pc_field_t\n",
    "\n",
    "                    for field_name_t, field_t in fields_t.items(): \n",
    "\n",
    "                        field_data_t = field_t\n",
    "                        for k, v in field_data_t.items():\n",
    "                            if k is None:\n",
    "                                data_t[field_name_t] = v\n",
    "                            else:\n",
    "                                data_t['%s.%s' % (field_name_t, k)] = v\n",
    "                    points_t = torch.tensor(data_t['points'], device=device)\n",
    "                    points_t = points_t[None,:]\n",
    "                    inputs_t = torch.tensor(data_t['inputs'], device=device)\n",
    "                    inputs_t = inputs_t[None,:]\n",
    "                    p_out_t = model(points_t, inputs_t)\n",
    "                    occ_hat_t = np.append(occ_hat_t, (p_out_t.probs >= 0.5).cpu().numpy())\n",
    "                occ_hat_t.astype('uint8').tofile(os.path.join(out_dir_ep, str(j).zfill(6) + '.label'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conv_onet] *",
   "language": "python",
   "name": "conda-env-conv_onet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
